var documenterSearchIndex = {"docs":
[{"location":"books/#人工智能","page":"-","title":"人工智能","text":"","category":"section"},{"location":"books/","page":"-","title":"-","text":"[ ] 王贺、刘鹏、钱乾《机器学习算法竞赛实战》\n[ ] 天池平台《阿里云天池大赛赛题解析 - 机器学习篇》\n[ ] 邱锡鹏《神经网络与深度学习》\n[ ] 《深度学习与目标检测：工具、原理与算法》  涂铭、金志勇\n[x] 《机器学习》  周志华\n[ ] 《深度学习推荐系统》  王喆\n[ ] 《机器学习》  汤姆 • 米切尔\n[x] 《百面机器学习》  诸葛越、葫芦娃\n[x] 《深度学习》  伊恩 • 古德费洛等\n[ ] 《图神经网络导论》  刘知远、周界\n[ ] 《深入浅出图神经网络：GNN 原理解析》  刘忠雨、李彦霖、周洋\n[ ] 《图神经网络基础与前沿》  马腾飞\n[x] 《Python Data Science Handbook: Essential Tools for Working with Data》  Jake VanderPlas\n[ ] 《PyTorch Computer Vision Cookbook》  Michael Avendi\n[ ] 《The Kaggle Book》  Konrad Banachewicz, Luca Massaron","category":"page"},{"location":"books/#编程语言","page":"-","title":"编程语言","text":"","category":"section"},{"location":"books/","page":"-","title":"-","text":"[ ] 《与孩子一起学编程 Warren Sande, Carter Sande｜零基础入门级别，Python 语言\n[ ] 《Python 编程快速上手》  Al Sweigart\n[ ] 《Python 编程：从入门到实践》  Eric Matthes\n[ ] 《设计模式：可复用面向对象软件的基础》Erich Gamma 等｜有史以来最伟大的软件开发书之一\n[ ] 《C 语言程序设计现代方法》K. N. King｜经典 C 语言的书\n[ ] 《C 陷阱与缺陷：C 语言调试指南》Andrew Koenig｜C 语言在泛型编程上的各种问题\n[ ] 《C++ Primer 中文版》Stanley B. Lippman｜学习 C++ 必看\n[ ] 《深度探索 C++ 对象模型》Stanley B. Lippman\n[ ] 《Effective C++：改善程序与设计的 55 个具体做法》Scott Meyers\n[ ] 《More Effective C++：35 个改善程序与设计的有效方法》Scott Meyers","category":"page"},{"location":"books/#操作系统","page":"-","title":"操作系统","text":"","category":"section"},{"location":"books/","page":"-","title":"-","text":"[ ] 《编码：隐匿在计算机软硬件背后的语言》Charles Petzold｜深度理解计算机工作原理\n[ ] 《鸟哥的 Linux 私房菜：基础学习篇》  鸟哥  有关于计算机和操作系统、Linux 系统\n[ ] 《Linux C 编程一站式学习》宋劲杉\n[ ] 《Linux/UNIX 系统编程手册》Michael Kerrisk\n[ ] 《Linux 系统编程》Robert Love\n[ ] 《Unix 编程艺术》Eric S. Raymond\n[ ] 《MySQL 必知必会》  Ben Forta\n[ ] 《数据库系统概念》Abraham Silberschatz｜斯坦福大学、耶鲁大学教科书\n[ ] 《现代操作系统》Andrew S• Tanenbaum｜进程、线程、存储管理、死锁\n[ ] 《计算机网络：自顶向下方法》James F. Kurose, Keith W. Ross｜\n[ ] 《计算机网络》Andrew S. Tanenbaum\n[ ] 《计算机程序的构造和解释》Harold Abelson｜MIT 计科教材，经典中的经典\n[ ] 《编译原理：原理、技术与工具》Alfred V. Aho｜又称「龙书」\n[ ] 《深入理解计算机系统》Randal E. Bryant, David O’ Hallaron｜最伟大的计算机教材之一\n[ ] 《Unix 环境高级编程》W. Richard Stevens, Stephen A. Rago\n[ ] 《UNIX 网络编程 卷 1：套接口 API》W. Richard Stevens 等\n[ ] 《UNIX 网络变成 卷 2：进程间通信》W. Richard Stevens\n[ ] 《TCP/IP 详解 卷 1：协议》W. Richard Stevens\n[ ] 《TCP/IP 网络编程》尹圣雨\n[ ] 《图解 TCP/IP》竹下隆史\n[ ] 《领域驱动设计：软件核心复杂性应对之道》Eric Evans\n[ ] 《架构整洁之道》Robert C. Martin\n[ ] 《操作系统导论》｜王海鹏版本的翻译不太好，可以简单过一遍","category":"page"},{"location":"books/#代码理论","page":"-","title":"代码理论","text":"","category":"section"},{"location":"books/","page":"-","title":"-","text":"[ ] 《编程珠玑》乔恩 • 宾利\n[ ] 《代码大全（第 2 版）》Steve McConnell｜旧书、厚、不太容易看\n[ ] 《算法》Robert Sedgewick, Kevin Wayne｜每个软件工程师应该会的 50 个算法\n[ ] 《算法图解》Aditya Bhargava\n[ ] 《算法导论》Thomas H. Cormen｜计算机专业的教材\n[ ] 《数据结构与算法分析》Mark Allen Weiss\n[ ] 《计算机程序设计艺术》系列 Donald E. Knuth｜包含一切基础算法的宝典\n[ ] 《剑指 Offer：名企面试官精讲典型编程题》何海涛","category":"page"},{"location":"books/#程序员的自我修养","page":"-","title":"程序员的自我修养","text":"","category":"section"},{"location":"books/","page":"-","title":"-","text":"[ ] Michael C. Feathers《修改代码的艺术》\n[ ] Robert C. Martin《代码整洁之道》代码质量与其整洁度成正比\n[ ] Robert C. Martin《代码整洁之道：程序员的职业素养》\n[ ] 《程序员修炼之道：通向务实的最高境界》  Andrew Hunt, David Thomas  如何成为高级软件工程师\n[ ] 《高效能程序员的修炼》Jeff Atwood｜博文选集\n[ ] 《重构：改善既有代码的设计》  Martin Fowler  教你如何构建优秀的代码\n[ ] 《人月神话》Frederick P. Brooks. Jr.｜如何管理复杂项目、过时但经典\n[ ] 《黑客与画家》Paul Graham｜「黑客」的爱好、动机、工作方法\n[ ] 《完美软件：对软件测试的各种幻想》Gerald M. Weinberg｜软件测试的心理问题\n[ ] 《Google 软件测试之道》James A. Whittaker","category":"page"},{"location":"AI/dataAnaly/#数据分析基本知识","page":"-","title":"数据分析基本知识","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：常用的 Python 库有哪些？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"NumPy：矩阵运算；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"Scikit-learn（sklearn）：常用机器学习和数据挖掘工具库；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"SciPy：基于 NumPy 做高效的数学计算，如积分、线性代数、稀疏矩阵等；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"Pandas：将数据用表的形式进行操作；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"Matplotlib：数据可视化工具；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"seaborn：数据可视化工具；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"Keras、TensorFlow、Theano：深度学习工具包；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"NLTK：自然语言处理工具包；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"beautifulsoap：网页文档解析工具；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：数据预处理过程有哪些？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"缺失值处理：删除、插入\n异常值处理\n特征转换：时间特征 sin 化表示\n标准化：最大最小标准化、Z 标准化等；\n归一化：对于文本或评分特征，不同样本之间可能有整体上的差异，如 a 文本共 20 个词，b 文本 30000 个词，b 文本中各个维度上的频次都很可能远远高于 a 文本；\n离散化：one-hot、分箱等；","category":"page"},{"location":"AI/dataAnaly/#数学知识","page":"-","title":"数学知识","text":"","category":"section"},{"location":"AI/dataAnaly/#参数估计","page":"-","title":"参数估计","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"参数估计是用样本统计量去估计总体的参数。它是统计推断的一种基本形式，是数理统计学的一个重要分支，分为点估计和区间估计两部分。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"参数估计 - 矩估计和极大似然估计概述","category":"page"},{"location":"AI/dataAnaly/#假设检验","page":"-","title":"假设检验","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"置信区间是我们所计算出的变量存在的范围，置信水平就是我们对于这个数值存在于我们计算出的这个范围的可信程度。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"统计学假设检验中 p 值的含义具体是什么？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"例如「有 95% 的把握，真正的数值在我们所计算的范围里」，这里 95% 是置信水平，而计算出的范围，就是置信区间。如果置信度为 95%， 则抽取 100 个样本来估计总体的均值，由 100 个样本所构造的 100 个区间中，约有 95 个区间包含总体均值。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"如何通俗地解释「置信区间」和「置信水平」？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：参数估计和假设检验的区别是什么？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"参数估计和假设检验是统计推断的两个组成部分，它们都是利用样本对总体进行某种推断，但推断的角度不同。参数估计讨论的是用样本估计总体参数的方法，总体参数 mu 在估计前是未知的。而在假设检验中，则是先对 mu 的值提出一个假设，然后利用样本信息去检验这个假设是否成立。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：协方差与相关系数的区别和联系是什么？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"协方差：表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"相关系数：研究变量之间线性相关程度的量，取值范围是 [-1,1]。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"相关系数也可以看成协方差：一种剔除了两个变量量纲影响、标准化后的特殊协方差。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：什么是中心极限定理？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"中心极限定理定义：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（1）任何一个样本的平均值将会约等于其所在总体的平均值。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（2）不管总体是什么分布，任意一个总体的样本平均值都会围绕在总体的平均值周围，并且呈正态分布。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"中心极限定理作用：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（1）在没有办法得到总体全部数据的情况下，我们可以用样本来估计总体。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（2）根据总体的平均值和标准差，判断某个样本是否属于总体。","category":"page"},{"location":"AI/dataAnaly/#降维算法","page":"-","title":"降维算法","text":"","category":"section"},{"location":"AI/dataAnaly/#主成分分析","page":"-","title":"主成分分析","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"主成分分析（PCA）是一种降维方法，思想是将样本从原来的特征空间转化到新的特征空间，并且样本在新特征空间坐标轴上的投影方差尽可能大，这样就能涵盖样本最主要的信息。数据投影的第一大方差在第一个坐标（称为第一主成分）上，第二大方差在第二个坐标（第二主成分）上。PCA 也可以看成是激活函数为线性函数的自动编码机","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"方法：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"特征归一化；\n求样本特征的协方差矩阵 A；\n求 A 的特征值和特征向量，即 AX=lambda X\n将特征值从大到小排列，选择前 K 个，对应的特征向量就是新的坐标轴；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：PCA 为什么要中心化？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"因为要算协方差。单纯的线性变换只是产生了倍数缩放，无法消除量纲对协方差的影响，而协方差是为了让投影后方差最大。","category":"page"},{"location":"AI/dataAnaly/#聚类算法","page":"-","title":"聚类算法","text":"","category":"section"},{"location":"AI/dataAnaly/#K-Means-算法","page":"-","title":"K-Means 算法","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：K-Means 算法原理及改进，遇到异常值怎么办？评估算法的指标有哪些？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"原理：在给定 K 值和 K 个初始类簇中心点的情况下，把每个点（即数据记录）分到离其最近的类簇中心点所代表的类簇中，所有点分配完毕之后，根据一个类簇内的所有点重新计算该类簇的中心点（取平均值），然后再迭代的进行分配点和更新类簇中心点的步骤，直至类簇中心点的变化很小，或者达到指定的迭代次数。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"改进：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"K-Means++：初始随机点选择尽可能远，避免陷入局部解。方法是 n+1 个中心点选择时，对于离前 n 个点选择到的概率更大；\nmini-batch K-Means：每次只用一个子集做重入类并找到类心（提高训练速度）；\nISODATA：对于难以确定 k 的时候，使用该方法。思路是当类下的样本小时，剔除；类下样本数量多时，拆分；\nkernel K-Means：K-Means 用欧氏距离计算相似度，也可以使用 kernel 映射到高维空间再聚类；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"当 K-Means 遇到异常值时：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"有条件的话使用密度聚类或者一些软聚类的方法先聚类，剔除异常值。不过本来用 K-Means 就是为了快，这么做就有些南辕北辙；\n局部异常因子 LOF：如果点 p 的密度明显小于其领域点的密度，那么点 p 可能是异常值；\n多元高斯分布异常点检测\n使用 PCA 或自动编码机进行异常点检测：使用降维后的维度作为新的特征空间，其降维结果可以认为剔除了异常值的影响（因为过程是保留使投影后方差最大的投影方向）；\nIsolation Forest：基本思路是建立树模型，一个节点所在的树深度越低，说明将其从样本空间划分出去越容易，因此越可能是异常值。是一种无监督的方法，随机选择 n 个sum sample，随机选择一个特征一个值；\nwinsorize：对于简单的，可以对单一维度做上下截取；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"异常点/离群点检测算法 —— LOF；Isolation Forest 算法原理详解；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"评估聚类算法的指标：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"外部法（基于有标注）：Jaccard 系数、纯度；\n内部法（无标注）：内平方和 WSS 和外平方和 BSS；\n此外还要考虑到算法的时间空间复杂度、聚类稳定性等；","category":"page"},{"location":"AI/dataAnaly/#决策树与随机森林","page":"-","title":"决策树与随机森林","text":"","category":"section"},{"location":"AI/dataAnaly/#随机森林","page":"-","title":"随机森林","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"原理：通过构造多个决策树，做 Bagging 来提高泛化能力；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"随机方法：subsample（有放回抽样）、subfeature、低维空间投影；","category":"page"},{"location":"AI/dataAnaly/#数据挖掘","page":"-","title":"数据挖掘","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"数据预处理：将原始数据进行集成、变换、维度规约、数值规约。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"其中 F 是快速性 (Fast)，指系统能在数秒内对用户的多数分析要求做出反应；A是可分析性(Analysis)，指用户无需编程就可以定义新的专门计算，将其作为分析的一部 分，并以用户所希望的方式给出报告；M是多维性(Multi—dimensional)，指提供对数据分析的多维视图和分析；I是信息性(Information)，指能及时获得信息，并且管理大容量信息。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"根据 OLAP 委员会的定义，联机分析处理 OLAP 是「使分析人员、管理人员或执行人员能够从多种角度对从原始数据中转化出来的、能够真正为用户所理解的并真实反映企业维特性的信息进行快速、一致、交互地存取，从而获得对数据的更深入了解的一类软件技术。」它具有 FASMI (Fast Analysis of Shared Multidimensional Information)，即共享多维信息的快速分析的特征。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"1）快速性：指系统能在数秒内对用户的多数分析要求做出反应。用户对 OLAP 的快速反应能力有很高的要求。系统应能在用户要求的时间内对用户的大部分分析要求做出反应，因此就更需要一些技术上的支持，如专门的数据存储格式、大量的事先运算、特别的硬件设计等。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"2）可分析性：指用户无需编程就可以定义新的专门计算，将其作为分析的一部 分，并以用户所希望的方式给出报告；OLAP 系统应能处理与应用有关的任何逻辑分析和统计分析。用户无需编程就可以定义新的专门计算，将其作为分析的一部分，并以用户理想的方式给出报告。用户可以在 OLAP 平台上进行数据分析，也可以连接到其他外部分析工具上，如时间序列分析工具、数据挖掘工具等。 ","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"3）多维性：指提供对数据分析的多维视图和分析。多维性是 OLAP 的关键属性。系统必须提供对数据分析的多维视图和分析，包括对层次维和多重层次维的完全支持。事实上，多维分析是分析企业数据最有效的方法，是 OLAP 的灵魂。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"4）信息性：指能及时获得信息，并且管理大容量信息。不论数据量有多大，也不管数据存储在何处，OLAP 系统应能及时获得信息，并且管理大容量信息。这里有许多因素需要考虑，如数据的可复制性、可利用的磁盘空间、OLAP 产品的性能及与数据仓库的结合度等。 ","category":"page"},{"location":"AI/dataAnaly/#关联规则挖掘","page":"-","title":"关联规则挖掘","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"Apriori 算法是在「购物篮分析」中常用的关联规则挖掘算法，在实际工作中需要对数据集扫描多次。2000 年时提出的 FP-Growth 算法只需要扫描两次数据集即可以完成关联规则的挖掘。其主要贡献就是提出了 FP 树和项头表，通过 FP 树减少了频繁项集的存储以及计算时间。Apriori 的改进算法除了 FP-Growth 算法以外，还有 CBA 算法、GSP 算法。","category":"page"},{"location":"AI/dataAnaly/#数据库","page":"-","title":"数据库","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"Hive 允许使用类 SQL 语句在 Hadoop 集群上进行读、写、管理等操作；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"Spark 是一种与 Hadoop 相似的开源集群计算环境，将数据集缓存在分布式内存中的计算平台，每轮迭代不需要读取磁盘的 IO 操作，从而大幅降低了单轮迭代时间；","category":"page"},{"location":"AI/dataAnaly/#面试问题","page":"-","title":"面试问题","text":"","category":"section"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：给定一个无序数组，怎么样才能合理采样？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"无序数组是相对有序数组而言的，无序数组并不等于随机，因此首先要做的是将无序数组洗牌，得到随机排列。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"对于无序数组，n 个元素能产生 n 种排序。如果洗牌算法能产生 n 种不同的结果，并且这些结果产生的概率相等，那么这个洗牌算法是正确的。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"Jiang_zzz，CSDN：数组的完全随机排列算法","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：行存储和列存储的区别？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"列式数据库更符合人类阅读习惯；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"行存储：传统数据库的存储方式，同一张表内的数据放在一起，插入更新很快。缺点是每次查询即使只涉及几列，也要把所有数据读取；\n列存储：OLAP 等情况下，将数据按照列存储会更加高效，每一列都可以成为索引，投影很高效。缺点是查询是选择完成时，需要对选择的列进行重新组装。\n当核心业务是 OLTP 时，一个行式数据库，再加上优化操作，可能是一个最好的选择。当核心业务是 OLAP 时，一个列式数据库，是更好的选择。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"列式存储和行式存储的区别为什么列存储数据库读取速度会比传统的行数据库快？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：男生点击率增加，女生点击率增加，总体为何减少？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"因为男女的点击率可能有较大差异，同时低点击率群体的占比增大。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"例如原来男性 20 人，点击 1 人；女性 100 人，点击 99 人，总点击率 100/120。现在变成男性 100 人，点击 6 人；女性 20 人，点击 20 人，总点击率 26/120。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：如何不用任何公开参考资料，估算今年新生儿出生数量？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"采用两层模型（人群画像 x 人群转化）：新生儿出生数=sum (各年龄层育龄女性数量times 各年龄层生育比率);\n从数字到数字：如果有前几年新生儿出生数量数据，建立时间序列模型（需要考虑到二胎放开的突变事件）进行预测;\n找先兆指标，如婴儿类用品的新增活跃用户数量 X 表示新生儿家庭用户。X_ntext新生儿_n 为该年新生儿家庭用户的转化率，如 X_2007text新生儿_2007 为 2007 年新生儿家庭用户的转化率。该转化率会随平台发展而发展，可以根据往年数量推出今年的大致转化率，并根据今年新增新生儿家庭用户数量推出今年估计的新生儿数量。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：如果次日用户留存率下降了 5% 该怎么分析？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"首先采用「两层模型」分析：对用户进行细分，包括新老、渠道、活动、画像等多个维度，然后分别计算每个维度下不同用户的次日留存率。通过这种方法定位到导致留存率下降的用户群体是谁。\n对于目标群体次日留存下降问题，具体情况具体分析。具体分析可以采用「内部-外部」因素考虑。\n内部因素分为获客（渠道质量低、活动获取非目标用户）、满足需求（新功能改动引发某类用户不满）、提活手段（签到等提活手段没达成目标、产品自然使用周期低导致上次获得的大量用户短期内不需要再使用等）；\n外部因素采用 PEST 分析（宏观经济环境分析），政治（政策影响）、经济（短期内主要是竞争环境，如对竞争对手的活动）、社会（舆论压力、用户生活方式变化、消费心理变化、价值观变化等偏好变化）、技术（创新解决方案的出现、分销渠道变化等）。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：卖玉米如何提高收益？价格提高多少才能获取最大收益？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"收益 = 单价times 销售量\n，那么我们的策略是提高「单位溢价」或者「提高销售规模」。\n提高单位溢价的方法：\n品牌打造获得长期溢价，但缺陷是需要大量前期营销投入；\n加工商品占据价值链更多环节，如熟玉米、玉米汁、玉米蛋白粉；重定位商品，如礼品化等；\n价格歧视，根据价格敏感度对不同用户采用不同定价。\n销售量=流量times 转化率\n，上述提高单位溢价的方法可能对流量产生影响，也可能对转化率产生影响。\n收益 = 单价times 流量times 转化率\n，短期内能规模化采用的应该是进行价格歧视，如不同时间、不同商圈的玉米价格不同，采取高定价，然后对价格敏感的用户提供优惠券等。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：类比到头条的收益，头条放多少广告可以获得最大收益？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"收益 = 出价times 流量times 点击率times 有效转化率","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"，放广告的数量会提高流量，但会降低匹配程度，因此降低点击率。最大收益是找到这个乘积的最大值，是一个有约束条件的最优化问题。同时参考价格歧视方案，可以对不同的用户投放不同数量的广告。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：APP 激活量的来源渠道很多，怎样对来源渠道变化大的进行预警？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"如果渠道使用时间较长，认为渠道的 APP 激活量满足一个分布，比较可能是正态分布。求平均值和标准差，对于今日数值与均值差大于 3/2/1 个标准差的渠道进行预警。\n对于短期的新渠道，直接与均值进行对比。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：用户刚进来 APP 的时候会选择属性，怎样在保证有完整用户信息的同时让用户流失减少？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"采用技术接受模型（TAM）来分析，影响用户接受选择属性这件事的主要因素有：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"技术接受模型提出了两个主要的决定因素：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"感知的有用性（perceived usefulness），反映一个人认为使用一个具体的系统对他工作业绩提高的程度；\n感知的易用性（perceived ease of use），反映一个人认为容易使用一个具体的系统的程度。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（1）感知有用性：文案告知用户选择属性能给用户带来的好处；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（2）感知易用性：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"关联用户第三方账号（如微博），可以冷启动阶段匹配用户更有可能选择的属性，推荐用户选择。\n交互性做好。","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（3）使用者态度：用户对填写信息的态度","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"这里需要允许用户跳过，后续再提醒用户填写\n告知用户填写的信息会受到很好的保护","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（4）行为意图：用户使用 APP 的目的性，难以控制","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（5）外部变量：如操作时间、操作环境等，这里难以控制","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"❓问：如何识别作弊用户，例如爬虫程序、渠道伪造的假用户？","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"分类问题可以用机器学习的方法去解决，下面是我目前想到的特征：","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（1）渠道特征：渠道、渠道次日留存率、渠道流量以及各种比率特征；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（2）环境特征：设备（一般伪造假用户的工作坊以低端机为主）、系统（刷量工作坊一般系统更新较慢）、WiFi 使用情况、使用时间、来源地区、IP 是否进过黑名单；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（3）用户行为特征：访问时长、访问页面、使用间隔、次日留存、活跃时间、页面跳转行为（假用户的行为要么过于一致，要么过于随机）、页面使用行为（正常用户对图片的点击也是有分布的，假用户的行为容易过于随机）；","category":"page"},{"location":"AI/dataAnaly/","page":"-","title":"-","text":"（4）异常特征：设备号异常（频繁重置 idfa）、IP 异常（异地访问）、行为异常（突然大量点击广告、点赞）、数据包不完整等；","category":"page"},{"location":"AI/CNN/#卷积神经网络","page":"-","title":"卷积神经网络","text":"","category":"section"},{"location":"AI/CNN/#深度卷积神经网络","page":"-","title":"深度卷积神经网络","text":"","category":"section"},{"location":"AI/CNN/","page":"-","title":"-","text":"感受野（Receptive Field），指的是神经网络中神经元「看到的」输入区域，在卷积神经网络中，feature map 上某个元素的计算受输入图像上某个区域的影响，这个区域即该元素的感受野。感受野是个相对概念，某层 feature map 上的元素看到前面不同层上的区域范围是不同的，通常在不特殊指定的情况下，感受野指的是看到输入图像上的区域。","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"例如两个级联的卷积核大小为 3times 3，stride = 2 的卷积层的感受野为 7times 7，如图所示","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"(Image: 感受野)","category":"page"},{"location":"AI/CNN/#卷积详解","page":"-","title":"卷积详解","text":"","category":"section"},{"location":"AI/CNN/#卷积","page":"-","title":"卷积","text":"","category":"section"},{"location":"AI/CNN/#因果卷积（Causal-Convolution）","page":"-","title":"因果卷积（Causal Convolution）","text":"","category":"section"},{"location":"AI/CNN/#空洞卷积","page":"-","title":"空洞卷积","text":"","category":"section"},{"location":"AI/CNN/","page":"-","title":"-","text":"空洞卷积具有更大的感受野，有助于构建长期记忆功能。","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"变形卷积","category":"page"},{"location":"AI/CNN/#CNN-历史","page":"-","title":"CNN 历史","text":"","category":"section"},{"location":"AI/CNN/#从-LeNet-5-到-ResNet","page":"-","title":"从 LeNet-5 到 ResNet","text":"","category":"section"},{"location":"AI/CNN/","page":"-","title":"-","text":"LeNet-5","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"AlexNet 首次亮相是在 2012 年的 ILSVRC 大规模视觉识别竞赛上，它的主要成果是将图像分类任务的 Top-5 错误率降低到 15.3%。AlexNet 主要的网络结构是堆砌的卷积层和池化层，最后在网络末端加上全连接层和 Softmax 层来处理多分类任务。AlexNet 的改进：","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"采用修正线性单元（Rectified Linear Unit，ReLU）作为激活函数（在此之前常用 Sigmoid 函数），缓解了深层网络训练时的梯度消失问题。\n引入局部响应归一化（Local Response Normalization，LRN）模块。\n应用 Dropout 和数据扩充（data augmentation）技术来提升训练效果。\n用分组卷积来突破当时 GPU 的显存瓶颈。","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"AlexNet 输入的图片大小为 227times 227，每个批次只有 1 张图片。","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"VGGNet 出现在2014 年的 ILSVRC 上，单个模型就将图像分类任务的 Top-5 错误率降低到 8.0%；如果采用多模型集成（ensemble），则可以将错误率进一步降至 6.8%。VGGNet 的改进：","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"VGGNet-16 输入的图片为 224times 224，每个批次有 10 张图片。","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"ResNet 的提出是为了解决网络退化（degeneration）的问题。退化是指随着网络层数的加深，网络的训练误差和测试误差都会上升。而过拟合是训练误差降低而测试误差反而升高的现象。ResNet-152 模型在 ImageNet 2012 数据集的图像分类任务上，单模型使得 Top-5 错误率降至 4.49%，采用多模型集成可以进一步将错误率降低到 3.57%。ResNet 的改进：","category":"page"},{"location":"AI/CNN/","page":"-","title":"-","text":"增加了跳跃连接（shortcut connection），在网络中构筑多条「近道」：\n缩短误差反向传播到各层的路径，有效抑制梯度消失的现象，使得网络在不断加深时性能不会下降。\n若网络在层数加深时性能退化，则它可以通过控制网络中「近道」和「非近道」的组合比例来退回到浅层时的状态，即「近道」具备自我关闭的能力。","category":"page"},{"location":"AI/CV/#快速索引目录","page":"-","title":"快速索引目录","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"常见神经网络结构：\nLeNet、AlexNet、VGGNet、GoogLeNet、ResNet、DenseNet、FPN\n两阶段检测算法：\nR-CNN 系列：R-CNN、Fast R-CNN、Faster R-CNN、Light-Hear R-CNN、Mask R-CNN\nSPPNet\n一阶段检测算法：\nYOLO、SSD、FCOS、RetinaNet、SENet\nATSS、Focal Loss、GFL","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"计算机视觉的任务有：图像分类、物体检测、语义分割、文字识别、人脸识别等","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"CV Baseline 数据：https://deepshare.feishu.cn/docx/doxcnDDF7Kmz7pGjfE7IY2Noppf","category":"page"},{"location":"AI/CV/#目标检测","page":"-","title":"目标检测","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"目标检测学习路径：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"理论：要求能够复现经典论文的代码","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"图像分类：VGG、Inception、ResNet、MobileNet、SENet\n图像分割：UNet、DeepLab 系列、FCN、SegNet、BiSeNet\n目标检测：YOLOv3、Faster R-CNN\nGAN：GAN、DCGAN、Pix2Pix","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"实践：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"数据增强技巧：MixUp、Label Smoothing\n长尾分布（Long-Tail）、渐进式采样（PB-sampling, Progressively-balanced Sampling）\n数据爬取与筛选：常规筛选方法（经典图像处理和分析方法）、高阶筛选方法（model-base，基于内容的筛选）\n语义分割：\n自动驾驶语义分割：CamVid 数据集，训练 UNet、SegNet；deeplabv3+ 进行模型评估和推理\n人像分割：Portrait 数据集；训练 BiseNet；Dice-Loss、CE Dice Loss、Focal Loss\n数据增强工具：Albumentations\n目标检测：\nYOLOX：Neck、Head、正负样本分配方式\nCOCO 数据集：Mosaic、Mixup、Affine 变化等数据增强方法\n轻量级目标检测器：NanoDetPlus\n算法终端部署：OpenVINO","category":"page"},{"location":"AI/CV/#基础概念","page":"-","title":"基础概念","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"计算特征图大小：计算经过卷积、池化等操作之后的特征图大小，这是一个十分常见的考题。假设特征图的输入尺寸为 l_i，Padding 大小为 p，卷积核或者池化核大小为 k，步长为 s，那么特征图的输出尺寸 l_o 计算公式为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"l_o=lfloorfracl_i+2p-ksrfloor+1","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 lfloorcdotrfloor 代表向下取整。很多深度学习框架会采取向下取整的方式，放弃输入特征图的一部分边界数据。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"计算感受野：假设网络的原始输入特征图的尺寸为 L，第 i 层卷积核（池化核）尺寸 k_i，第 j 层的步长为 s_j，则第 i 层的感受野大小 R_i 计算如下","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"R_i=minleft( R_i-1 + (k_i-1)prod_j=0^i-1s_j L right)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中对于原始输入层 R_0=1 s_0=1. ","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"目标检测（Object Detection）是计算机视觉中极为重要的基础问题，是实例分割（Instance Segmentation)、场景理解（Secne Understanding）、目标跟踪（Object Tracking）、图像标注（Image Captioning）等问题的基础。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"目标检测任务：给定一张图片，将图片中的每个物体识别出来并且提出一个置信度，用矩形方框（Bounding Box）或者不规则的区域标识出来。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"目标检测模型分为单步（one-stage）模型和两步（two-stage）模型两大类。单步模型在计算效率上有优势，两步模型在检测精度上有优势。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"单步模型是指没有独立地、显式地提取候选区域（region proposal），直接由输入图像得到其中存在的物体的类别和位置信息的模型。例如 OverFeat、SSD（Single Shot multibox-Detector）、YOLO（You Only Look Once） 等模型。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"两步模型是指有独立的、显式的候选区域提取过程，即先在输入图像上筛选出一些可能存在物体的候选区域，然后针对每个候选区域，判断其是否存在物体，如果存在就给出物体的类别和位置修正信息。例如 R-CNN、SPPNet、Fast R-CNN、Faster R-CNN、R-FCN、Mask R-CNN 等模型。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"交并比（Intersection-over-Union，IoU）：即两个 Bounding Boxes 之间交集与并集的比值。对于预测 Bounding Box 与 Ground-truth Box 来说，比值越大代表预测的 Bounding Box 结果越好。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"可以学习一下 IoU 的 Python 代码 IoU_demo.py。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"# 这六行短短的代码可以囊括所有 pred bbox 和 gt bbox 之间的关系。包括相交、不相交、各种相交形式等等\nixmin = max(pred_bbox[0], gt_bbox[0])\niymin = max(pred_bbox[1], gt_bbox[1])\nixmax = min(pred_bbox[2], gt_bbox[2])\niymax = min(pred_bbox[3], gt_bbox[3])\niw = np.maximum(ixmax - ixmin + 1., 0.)\nih = np.maximum(iymax - iymin + 1., 0.)\n\ninters = iw * ih  # 交集\nuni = ((pred_bbox[2] - pred_bbox[0] + 1.) * (pred_bbox[3] - pred_bbox[1] + 1.) +\n           (gt_bbox[2] - gt_bbox[0] + 1.) * (gt_bbox[3] - gt_bbox[1] + 1.) -\n           inters)  # 并集 union = S1 + S2 - inters\n\noverlaps = inters / uni  # IoU","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"均交并比（Mean Intersection over Union, MIoU）：MIoU 是语义分割的标准度量，其计算两个集合的交集和并集之比。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textMIoU=frac1k+1sum^k_i=0fracp_iisum_j=0^kp_ij+sum_j=0^kp_ji-p_ii","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 p_ij 表示真实值为 i，被预测为 j 的数量。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"橙色是真实值，蓝色是预测值，中间是两个部分的相交部分。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"均像素精度（Mean Pixel Accuracy, MPA）：预测正确的部分占整个真实值的比例，或者说真正例占假负例的比例，即面积 3 和面积 1 的比例。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"而 MIoU 就是两个部分交集部分与并集部分的比，越接近 1 证明预测结果越好，最理想的情况是 1. ","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"非极大值抑制（Non-Maximum Suppression，NMS）：目标检测过程中在同一个目标的位置上会产生大量的候选框，这些候选框之间可能会有重叠，NMS 的作用就是消除冗余的边界框，找到最佳的目标边界框。NMS 的流程如下：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"步骤 1. 根据置信度得分进行排序；\n步骤 2. 选择置信度最高的边界框添加到最终输出列表中，将其从边界框列表中删除；\n步骤 3. 计算所有边界框的面积；\n步骤 4. 计算置信度最高的边界框与其他候选框的 IoU；\n步骤 5. 删除 IoU 大于给定阈值的边界框；\n步骤 6. 重复上述过程，直到边界框列表为空；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"NMS 中的阈值给得越大，则越有可能出现同一个物体有多个边界框的情况。步骤 4 中如果置信度最高的边界框与其他候选框的 IoU 比较大的话，就可以认为这两个边界框中是同一个物体，因此只要留下最大的那一个，把其他的删除了。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"代码：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"out = net(x)  # forward pass, 将图像 x 输入网络，得到 pred cls + reg\nboxes, scores = detector.forward(out, priors)  # 结合 priors，将 pred reg（即预测的 offsets）解码成最终的 pred bbox\nboxes = boxes[0]\nscores = scores[0]\n\n# scale each detection back up to the image\nboxes *= sca;e  # (0, 1) 区间坐标的 bbox 做尺度反正则化\nboxes = boxes.cpu().numpy()\nscores = scores.cpu().numpy()\n\nfor\tj in range(1, num_classes):  # 对每一个类 j 的 pred bbox 单独做 NMS\n    # 因为第 0 类是 background，不用做 NMS，因此 index 从 1 开始\n    inds = np.where(scores[:, j] > thresh)[0]  # 找到该类 j 下，所有 cls score 大于 thresh 的 bbox\n    # score 小于阈值的 bbox 直接过滤掉，不用进行 NMS\n    if len(inds) == 0:  # 没有满足条件的 bbox，返回空，跳过\n        all_boxes[j][i] = np.empty([0, 5], dtype=np.float32)\n        continue\n    c_bboxes = boxes[inds]\n    c_scores = scores[inds, j]  # 找到对应类 j 下的 score 即可\n    c_dets = np.hstack((c_bboxes, c_scores[:, np.newaxis])).astype(np.float32, copy=False)  # 将满足条件的 bbox + cls score 的 bbox 通过 hstack 完成合体\n    \n    keep = nms(c_dets, 0.45, force_cpu=args.cpu)  # NMS，返回需要保存的 bbox index: keep\n    c_dets = c_dets[keep, :]\n    all_boxes[j][i] = c_dets  # i 对应每张图片，j 对应图像中类别 j 的 bbox 清单","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"True Positive (TP)：textIoU  05 的检测框数量（同一个 Ground Truth 只计算一次）","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"False Positive (FP)：textIoUle 05 的检测框（检测到同一个 Ground Truth 的多余检测框的数量","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"False Negative (FN)：没有检测到的 Ground Truth 的数量","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"True Negative (TN)：在 mAP 评价指标中不会使用到","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"查准率（Precision）：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textPrecision = fractextTP(textTP + textFP) = fractextFPtextall detections","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"查全率、查全率（Recall）：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textRecall = fractextTP(textTP+textFN)=fractextTPtextall ground truths","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"PR 曲线（Precision-Recall Curve）：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"平均精确度（Average Precision）：PR 曲线下面积","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"mAP（mean Average Precison）：各类别 AP 的平均值。在 VOC2010 以前（VOC07），只要选择当 textRecallge 0 01 02 dots 1 共 11 个点时的 Precision 最大值，然后 AP 就是这 11 个 Precision 的平均值；在 VOC2010 开始，需要针对每一个不同的 Recall 值（包括 0 和 1），选取其大于等于这些 Recall 值时的 Precision 最大值，然后计算 PR 曲线下面积作为 AP 值。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"通常 VOC10 标准下计算的 mAP 值会高于 VOC07，原因如下：插值平均精度（Interpolated Average Precision）：一些作者选择了另一种近似值，称为插值平均精度。 通常，他们仍然称其为平均精度。 这种方法不使用 P(k)，在 k 个图像的截止处的精度，插值平均精度使用：max_tildekge kP(tildek)换句话说，插值平均精度不是使用在截止 k 处实际观察到的精度，而是使用在所有具有更高召回率的截止上观察到的最大精度。计算插值平均精度的完整方程为：sum_k=1^Nmax_tildekge kP(tildek)Delta r(k)近似平均精度（Approximated Average）与实际观察到的曲线非常接近。 插值平均精度高估了许多点的精度，并产生比近似平均精度更高的平均精度值。此外，在计算插值平均精度时，在何处采集样本存在差异。 有些人在从 0 到 1 的固定 11 个点采样：0 01 02  09 10。 这称为 11 点插值平均精度。 其他人在召回率发生变化的每个 k 处采样。","category":"page"},{"location":"AI/CV/#目标检测历史","page":"-","title":"目标检测历史","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"在一开始的 CNNs 上，把一张图片划分成为固定的区域，然后识别这些区域中是否有某个物体，有的话就把这个区域标识出来。但是在实际中，图片上的物体大小是不固定的，用这种固定大小的区域去识别物体显然是不合理的。人们想到，如果想要让框更加合适，可以增加框的数量，然后让每个区域都变得尽可能地小。但是这样框太多的时候，又会导致计算量的增加。","category":"page"},{"location":"AI/CV/#常见神经网络结构","page":"-","title":"常见神经网络结构","text":"","category":"section"},{"location":"AI/CV/#LeNet","page":"-","title":"LeNet","text":"","category":"section"},{"location":"AI/CV/#AlexNet","page":"-","title":"AlexNet","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"首次出现在 2012 年，由 神经网络的坚守者 Hinton 和他的学生 Alex Krizhevsky 设计，在 ImageNet LSVRC-2010 测试集上的 Top-1 和 Top-5 错误率为 37.5% 和 17.0%。AlexNet 有 6 亿个参数和 650, 000 个神经元，5 个卷积层，3 个全连接层，最后一个全连接层通过 Softmax 产生的结果作为输入图像在 1000 个类别上的得分，在全连接层使用 Dropout 减少过拟合。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"整个网络的结构：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"输入为一个 (227 227 3) 的图像；\n第一层卷积由 96 个大小为 (11 11 3) 的卷积核组成，滑动步长 stride 为 4，无 padding，因此第一个卷积层输出层尺寸为 (55 55 96)；\n后接 Max Pooling，大小为 3times 3，步长为 2，无 padding，输出特征图的尺寸为 (27 27 96)；\n第二层卷积由  256 个大小为 (5 5 96) 的卷积核组成，步长为 1，padding 为 2，输出特征图尺寸为 (27 27 256)；\n后接 Max Pooling，大小为 3times 3，步长为 2，无 padding，输出特征图的尺寸为 (13 13 256)；\n第三层卷积由 384 个大小为 (3 3 256) 的卷积核组成，步长为 1，padding 为 1，输出特征图尺寸为 (13 13 384)；\n第四层卷积由 384 个大小为 (3 3 384) 的卷积核组成，步长为 1，padding 为 1，输出特征图尺寸为 (13 13 384)；\n第五层卷积由 256 个大小为 (3 3 384) 的卷积核组成，步长为 1，padding 为 1，输出特征图尺寸为 (13 13 256)；\n后接 Max Pooling，大小为 3times 3，步长为 2，无 padding，输出特征图尺寸为 (66256)；\n后面是三层全连接层，最后一层是 Softmax，有 1000 个类别；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"卷积输出层分辨率计算公式：(W+2times textpadding - textkernel)textstride + 1","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"AlexNet 的特点：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"是第一个使用卷积神经网络在 ILSVRC 比赛中获得冠军的网络结构；\n使用 ReLU 作为激活函数，替代传统神经网络神经元激活函数 Tanh 和 Sigmoid，提高了收敛速度；\n使用多种方法避免过拟合：\n数据增强：每个 (256 256) 的样本被裁剪成 (224 224) 的大小（可以有 (256-224)^2=1024 个），再做一次水平翻转，因此一个样本可以扩增为 2048 个；\n在测试集上，对 (256 256) 的图像做四个角和中间部分的裁剪，再做水平翻转，每个测试样本有 10 个 Patches，最终对模型的输出结果取平均；\n改变 RGB 图像的亮度；\n在前两个全连接层上使用 Dropout：使用 0.5 随机失活的 Dropout；在测试时将神经元的输出结果乘以 0.5；\n使用双 GPU 并行训练（这个是因为当时的计算力限制）；\n局部响应归一化：在第 1、2 个卷积层之后使用了局部响应归一化；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"数据增强的方法有随机裁剪、随机上下左右翻转、平移、缩放、旋转、修改图像饱和度、颜色、亮度等","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"局部响应归一化（Local Response Normalization，LRN）：是一种受生物学启发的归一化方法，通常用在基于卷积的图像处理上，LRN 对邻近的特征映射进行局部归一化。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"假设一个卷积层的输出特征映射 boldsymbolYinmathbbR^M^primetimes N^primetimes P 为三维张量，其中每个切片矩阵 boldsymbolY^pinmathbbR^M^primetimes N^prime 为一个输出特征映射，1le ple P，那么 LRN 计算如下：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"hatboldsymbolY^p=boldsymbolY^pleft( k + alphasum_j=max(1 p-fracn2)^min(P p+fracn2)(boldsymbolY^j)^2right)^beta triangleq textLRN_nkalphabeta(boldsymbolY^p)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中除和幂运算都是按元素运算，nkalphabeta 为超参，n 为局部归一化的特征窗口。在 AlexNet 中，n=5k=2 alpha=10e^-4beta=075","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"局部响应归一化（LRN）和层归一化（Layer Normalization，LN）的异同：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"都是对同层的神经元进行归一化；\nLRN 应用在激活函数之后，只是对邻近的神经元进行局部归一化，并且不减去均值；\nLN 是对一个中间层的所有神经元进行归一化；\nLRN 与生物神经元中的侧抑制（lateral inhibition）现象类似，即活跃神经元对相邻神经元具有抑制作用；当使用 ReLU 作为激活函数时，神经元的活性值是没有限制的，LRN 可以起到平衡和约束作用；\n如果一个神经元的活性值非常大，那么和它邻近的神经元就近似地归一化为 0，起到抑制作用，可以增强模型的泛化能力；\n最大汇聚（Max Pooling）也具有抑制作用，区别在于最大汇聚是对同一个特征映射中的邻近位置中的神经元进行抑制，LRN 是对同一个位置的邻近特征映射中的神经元进行抑制；","category":"page"},{"location":"AI/CV/#VGGNet","page":"-","title":"VGGNet","text":"","category":"section"},{"location":"AI/CV/#GoogLeNet","page":"-","title":"GoogLeNet","text":"","category":"section"},{"location":"AI/CV/#ResNet","page":"-","title":"ResNet","text":"","category":"section"},{"location":"AI/CV/#DenseNet","page":"-","title":"DenseNet","text":"","category":"section"},{"location":"AI/CV/#FPN","page":"-","title":"FPN","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"特征金字塔网络（Feature Pyramid Networks，FPN）：低层的特征语义信息比较少，但是目标位置准确；高层的特征语义信息比较丰富，但是目标位置比较粗略。有些算法采用多尺度特征融合的方法，但是一般是采用融合后的特征做预测。这篇文章创新的点在于预测是在不同特征层独立进行的。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"论文中的图 1 展示了 4 种利用特征的方式：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"图像金字塔（Featurized image pyramid）：将图像 reshape 为不同的尺度，不同尺度的图像生成对应不同尺度的特征。这种方式缺点在于增加了时间成本；\n单个特征图（Single feature map）：像 SPPNet、Fast R-CNN、Faster R-CNN 等模型采用的方式，只使用最后一层的特征图；\n金字塔特征层次结构（Pyramidal feature hierarchy）：像 SSD 模型采用多尺度特征融合的方式，没有上采样的过程，从网络不同层抽取不同尺度的特征做预测。优点在于不会增加额外的计算量；缺点在于 SSD 没有用到足够底层的特征（SSD 中最底层的特征是 VGG 网络的 Conv4_3）；\n特征金字塔网络（Feature Pyramid Network）：顶层特征通过上采样和低层特征做融合，每层独立预测；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"论文的图 2 展示的是两种不同的金字塔结构，上面的结构将最顶部最小的特征图进行上采样之后与前面阶段的特征图相融合，最终只在最底层最大的特征图（自顶向下的最后一层也可以叫做 Finest Level）上进行预测。下面的结构预测是在每一层中独立进行的。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"论文的算法结构如图 3 所示，其结构包括一个自底向上的路径（bottom-up pathway）、自顶向下的路径（top-down pathway）以及横向连接（lateral connections），1times 1 卷积层的主要作用是减少卷积核的个数。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Bottom-Up Pathway 是网络的前向过程。论文将不改变 feature map 大小的层视为在同一个网络阶段（stage），每次抽取出来的 feature map 都是每个 stage 的最后一层输出，因为最后一层的特征是最强的，每个阶段的 feature map 记为 C_2 C_3 C_4 C_5。\nTop-Down Pathway 过程采用上采样（Upsampling）进行，生成的 feature map 记为 P_2 P_3 P_4 P_5。\nLateral Connections 是将上采样的结果和自底向上生成的相同大小的 feature map 进行融合（merge）。\n在融合过后会使用 3times 3 卷积对每个融合结果进行卷积，以消除上采样的混叠效应（Aliasing Effect）。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"将 FPN 用于 RPN 网络中生成 Region Proposal，在每一个 stage 都定义了不同大小的 anchor，对于 P_2 P_3 P_4 P_5 P_6 分别为 32^2 64^2 128^2 256^2 512^2，每种尺度的 anchor 有不同的比例 12 11 21，整个特征金字塔有 15 种 anchors。","category":"page"},{"location":"AI/CV/#两阶段检测算法","page":"-","title":"两阶段检测算法","text":"","category":"section"},{"location":"AI/CV/#R-CNN","page":"-","title":"R-CNN","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"基于区域的卷积神经网络（Region-based CNN，R-CNN）出现于 2014 年，是第一个将 CNN 用于目标检测的深度学习模型。它是是解决这种缺点的更好方法，它使用生成区域建议的方式来选择区域。R-CNN 的选框方式是根据选择性搜索来进行的，选框也叫做区域（regions）。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"首先使用无监督的选择性搜索（Selective Serch，SS）方法将图像中具有相似颜色直方图特征的区域进行合并，产生 2000 个大小不一样的候选区域。这个最后合成的区域就是物体在图片中的位置，即感兴趣区域（Region of Interest，RoI）；\n然后从输入图像中截取这些候选区域对应的图像，将其裁剪缩放 reshape 至合适的尺寸，并相继送入一个 CNN 特征提取网络进行高层次的特征提取；\n提取出的特征再被送入一个支持向量机（Support Vector Machine，SVM）来对这些区域进行分类，以及一个线性回归器进行边界框位置和大小的修正，即边界框回归（Bounding Box Regression）；\n最后对检测结果进行非极大值抑制（Non-Maximum Suppression，NMS），得到最终的检测结果；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"R-CNN 的不足：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"每一张图片都会生成很多个 RoI；\n整个过程用了三个模型：特征提取的 CNN、物体分类的 SVM、预测边界框的回归模型，让 R-CNN 变得非常慢，预测一张图片要几十秒；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"选择性搜索（Selective Serch，SS）：一个物体会包括四种信息：不同的尺度、颜色、纹理和边界，选择性搜索目标就是识别这些模式，提出不同的区域。首先，先生成最初的分割得很细的子分割，然后再将这些很细的小区域按照颜色相似度、纹理相似度、大小相似度和形状相似兼容性来合并成更大的感兴趣区域 RoI。","category":"page"},{"location":"AI/CV/#SPPNet","page":"-","title":"SPPNet","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"SPPNet 出现于 2015 年，","category":"page"},{"location":"AI/CV/#Fast-R-CNN","page":"-","title":"Fast R-CNN","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"Fast R-CNN 出现于 2015 年，它添加了一个 RoI 池化层（RoI Pooling Layer）来把所有的建议区域转换成适合的尺寸，输入到后面的全连接层（Fully Connection）。Fast R-CNN 将 R-CNN 的三个独立的模型集合到一个模型中，因为减少了很多的计算量，Fast R-CNN 在时间花费大大地减少了。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"具体步骤为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"图片通过 CNN 得到 RoI，然后 RoI 池化层将 RoI 改变成相同的尺寸；\n再将这些区域输入到全连接层上进行分类，同时使用 softmax 和线性回归层（Linear Regression Layers）来输出 Bounding Boxes；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"RoI 池化层（RoI Pooling Layer）：目的是对非均匀尺寸的输入执行最大池化以获得固定尺寸的特征图。RoI 池化层的原型是何凯明提出的空间金字塔池化（Spatial Pyramid Pooling），RoI 池化是 SPP 只使用其中一层的特殊情况。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"RoI Pooling 接收卷积特征图作为输入；\n将 RoI 分割为 Htimes W 个网格（论文中为 7times 7），对每一个网格都进行 max pooling 得到最终 Htimes W 大小的特征图；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"下面是 RoI Pooling 的一个 GIF 示例：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Fast R-CNN 的优势和不足：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"依然在使用选择性搜索来作为寻找 RoI 的方法，虽然速度提高了，但是一张图片依旧需要花费 2 秒的时间。","category":"page"},{"location":"AI/CV/#Faster-R-CNN","page":"-","title":"Faster R-CNN","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"Faster R-CNN 出现于 2017 年，它使用一个区域建议网络（Region Proposal Network，RPN）来获得比 Fast R-CNN 更高的效率。RPN 将图片特征 map 作为输入，生成一系列带目标分数的建议，也就是告诉网络给出的区域有物体的可能性有多大，分数越高代表包含了物体的可能性越高。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"具体步骤：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"把图片作为输入放进卷积网络中去，返回的是一个特征映射（feature map）；\nRPN 处理这些 map，返回带分数的物体建议；\n接下来的 RoI pooling 把这些建议都 reshape 成相同的尺寸；\n最后，放到含有 softmax 层和线性回归层的全连接层上，来分类和输出 bounding boxes。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"RPN 被集成在了网络里面，等于从区域建议到最后的分类回归都在同一个网络，实现了端到端。即我们给这个网络输入一张图片，网络就会输出 bounding boxes 和分数。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"区域建议网络（Region Proposal Network，RPN）：可以输入任何大小的图片（或者特征映射图），然后输出一系列目标建议矩形框，每个矩形框都会有一个对应的分数，代表这个框里面有多大的概率是一个物体。在 Faster R-CNN 中 RPN 是一个全卷积网络（Fully-Convolutional Network，FCN）","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"图中的数据，在原论文中的具体值为：C_2=256 text or  512，H=W=16，k=9. ","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"RPN 实际上可以看成是一个小型的 CNN，原文说的是它在 feature map 上使用一个大小为 ntimes n 的滑动窗口（sliding window），在 Faster R-CNN 论文里 n=3：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"步骤 1：实际上 RPN 就是一个 3times 3 的卷积层，将维数（或者说通道数 Channel）为 C_1 的特征图 1 映射成维度为 C_2 的特征图 2（在 Faster R-CNN 论文中，在使用 ZF 模型时 C_2=256，在使用 VGG 模型时 C_2=512）；\n步骤 2：这个特征图 2 会分别进入两个 1times 1  卷积层，一个做矩形框分类（判断是否为物体），对应特征图 3-1，另一个做矩形框回归，对应特征图 3-2。1times 1 卷积的作用是压缩通道数（Channel），图中用于矩形框分类的特征图 3-1 通道数变为 2k，用于矩形框回归的特征图 3-2 通道数变为 4k，这里的 k 是 anchor boxes 的数量（在论文里取 k=9）。分类部分的维度为 2，分别表示框出的部分为「目标」与「非目标」的概率；回归部分的维度为 4，分别表征不同 anchor boxes 对 groud-truth 的长、宽、X 坐标、Y 坐标的预测；\n在训练的时候，只有 RPN 输出的区域建议与 groud-truth 的 textIoU07 的 anchor boxes 与 groud-truth 的位置大小误差才会对最终的损失 mathcalLoss 有贡献。\n对于特征图 1 中的每一个 ntimes n 的滑动窗口， RPN 输出 k 个区域建议，这 k 区域建议都是由 k 个 anchor boxes 作为基准调整得到的。特征图 1 中的每一个点都可以对应到原图的某个点，这个点称为锚点（anchor）。\n在论文中，对于每一个 anchor，以其为中心选择 9 个不同大小和不同长宽比的 anchor boxes，具体为 128^2 256^2 512^2 三种尺度，每个尺度按 11 12 21 的 3 种长宽比例进行缩放，因此一共有 9 个。\n实际上 RPN 并不是直接预测最终的区域建议，而是调节所有的 anchor boxes 并且经过非极大值抑制得到最终的区域建议。对于一个大小为 Htimes W 的特征图，会有 kHW 个 anchor boxes。\n对于每个 anchor，如果满足两种情况：（1）与 ground-truth box 有最大的 IoU（并不一定会大于 0.7）；（2）与 ground-truth 的 IoU 大于 0.7，那么给其分配正标签，表示预测的效果是好的；如果与 ground-truth 的 IoU 小于 0.3 那么给其分配负标签，表示预测的结果很差。除了这些情况，其他的 anchor 不会对对损失函数有贡献。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Faster RCNN 的损失函数由 4 个部分组成：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"RPN 分类损失：anchor 是否为 Ground Truth，二类交叉熵损失；\nRPN 位置回归损失：anchor 位置微调，bbox 的第一次修正；\nRoI 分类损失：RoI 所属类别，分类损失；\nRoI 位置回归损失：继续对 RoI 位置微调，第二次对 bbox 的修正；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"最终的损失是这 4 个损失相加。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"对于每一个图片，损失函数为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Lleft( p_it_i right) = frac1N_clssum_iL_cls(p_ip_i^*) + lambdafrac1N_regsum_ip_i^*L_reg(t_it_i^*)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中，i 是 mini-batch 中 anchor 的索引，p_i 是第 i 个 anchor 中为物体的预测概率。对于 ground-truth label  p_i^*，如果 anchor 是正标签那么其为 1，如果为负标签那么其为 0。t_i 为一个向量，表示所预测的边界框（Bounding Box）的 4 个坐标，t_i^* 表示正标签 anchor 所对应的 ground-truth box 的坐标。分类损失 L_cls 是两个类别（「目标」与「非目标」）的对数损失（Log Loss）；回归损失 L_reg(t_it_i^*)=R(t_it_i^*). ","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Faster R-CNN 的优势和不足：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"通过使用端到端的方式去进行，并且也不会考虑所有的 RoI，处理一张图片只需要 0.2 秒。","category":"page"},{"location":"AI/CV/#Light-Head-R-CNN","page":"-","title":"Light-Head R-CNN","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"Light-Head R-CNN 出现于 2017 年","category":"page"},{"location":"AI/CV/#Mask-R-CNN","page":"-","title":"Mask R-CNN","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"Mask R-CNN 出现于 2017 年","category":"page"},{"location":"AI/CV/#一阶段检测算法","page":"-","title":"一阶段检测算法","text":"","category":"section"},{"location":"AI/CV/#YOLO","page":"-","title":"YOLO","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"YOLO 出现于 2016 年","category":"page"},{"location":"AI/CV/#SSD","page":"-","title":"SSD","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"SSD 出现于 2016 年","category":"page"},{"location":"AI/CV/#FCOS","page":"-","title":"FCOS","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"发表于 ICCV2019 的论文：FCOS: Fully Convolutional One-Stage Object Detection 提出了 FCOS，与 YOLO 类似，它直接将 backbone 输出的 feature map 上的每一个像素当做预测起点，即把每一个位置都当做训练样本，只要该位置落入某个 Ground-Truth 框，就将其当做正样本进行训练。为了让一个目标在推理时不会在多个 feature map 上被重复输出，认为限制了每一层回归目标的尺度大小，超过该限制的目标，这一层就不检测。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"论文中图 2 展示了 FCOS 的具体结构：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"FCOS 在检测头增加一个中心度（Centerness）分支，保证回归框的中心和 GT 较为接近，同时和 FPN 结合，在每一层上只回归特定大小的目标，从而将不同尺度的目标分配到对应层级上","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textcenterness^*=sqrtfracmin(l^*r^*)max(l^*r^*)times fracmin(t^*b^*)max(t^*b^*)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 ","category":"page"},{"location":"AI/CV/#RetinaNet-(Focal-Loss)","page":"-","title":"RetinaNet (Focal Loss)","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"推荐阅读：MMDetection；\nGitHub：MMDetection；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"何凯明在 ICCV2017 上的新作 Focal Loss for Dense Object Detection 提出了一个一个新的损失函数 —— Focal Loss，主要用于解决在单阶段目标检测场景上训练时前景（foreground）和背景（background）类别极端失衡（比如 1:1000）的问题。Focal Loss 可以抑制负样本对最终损失的贡献以提升网络的整体表现。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"将不含有待检测物体的区域称为负样本，含有待检测物体的区域称为正样本。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Focal Loss 的最终形式为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textFL(p_t)=-alpha_t(1-p_t)^gammalog(p_t)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"演变过程如下，一般来说，对于二分类问题，交叉熵损失为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textCE(py)=begincases-log(p)qquad textif  y=1 -log(1-p)quad textotherwise endcases","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 yinpm 1 是类别标签，pin0 1 是模型对于样本类别属于 y=1 的预测概率，定义","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"p_tbegincasesp qquad textif  y=1 1-p quad textotherwise endcases","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"因此交叉熵损失可以重写为 textCE(py)=textCE(p_t)=-log(p_t)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"这里应该区分的一个点是：难易样本不平衡和正负样本不平衡，Focal Loss 主要是在解决难易样本不平衡的问题上。一般解决正负样本不平衡的问题，会在交叉熵损失前面加上一个参数 alpha 得到","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textCE(p_t)=-alpha_tlog(p_t)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"只是这样的方案只能解决正负样本不平衡的问题，至于难易样本不平衡，Focal Loss 的思想就是降低高置信度样本的损失：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textFL(p_t)=-(1-p_t)^gammalog(p_t)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"假设 gamma=2 时，如果样本置信度为 p=0968，那么 (1-0968)^2approx 0001 就可以将这个高置信度样本的损失衰减 1000 倍。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"将增加参数 alpha 添加到 Focal Loss 上就可以同时解决正负以及难易样本不平衡的问题，最终 Focal Loss 的形式为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textFL(p_t)=-alpha_t(1-p_t)^gammalog(p_t)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"在 MMDetection 的 GItHub 开源代码中可以看到对于 Focal Loss 实现的 Python 代码，实际上真正使用的是 CUDA 版本代码，因此这里给出的代码只是供人学习的。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Focal Loss 存在的问题：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"模型过多地关注那些特别难分的样本 —— 离群点（outliers），即便是模型已经收敛了，但是这些离群点依旧是","category":"page"},{"location":"AI/CV/#SENet","page":"-","title":"SENet","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"目标检测中的注意力机制","category":"page"},{"location":"AI/CV/#ATSS","page":"-","title":"ATSS","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"论文 Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection 中提出了一种根据目标的统计信息自动选择正负样本的自适应样本选择机制（Adaptive Training Sample Selection，ATSS）。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"论文里提到无论是 anchor-based 方法还是 anchor-free 方法，","category":"page"},{"location":"AI/CV/#GFL","page":"-","title":"GFL","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"推荐阅读：GFL 作者本人 李翔 的文章 知乎：大白话 Generalized Focal Loss；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"论文 Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection 所提出的 广义焦点损失（Generalized Focal Loss，GFL）的具体形式如下：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textGFL(p_y_l p_y_r)=-y-(y_l p_y_l+y_rp_y_r)^betaleft( (y_r-y)log(p_y_l) + (y-y_l)log(p_y_r)right)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"GFL 主要解决两个问题：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"在训练和推理的时候，分类和质量估计的不一致性；\n狄拉克分布针对复杂场景下（模糊和不确定性边界）存在不灵活的问题；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"解决这两个问题的方式是设计新的「表示」方法：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"通过联合质量估计和分类设计新的 Loss；\n定义一种新的边界框表示方式来进行回归；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"GFL 工作的核心是围绕表示（representation）的改进去进行的，表示具体是指检测器最终的输出，也就是 head 末端的物理对象，以 FCOS、ATSS 为代表的 one-stage anchor-free 检测器基本会包含 3 个表示：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"分类表示；\n检测框表示；\n检测框的质量估计。在 FCOS、ATSS 中采用 centerness，一些其他的工作会采用 IoU，这些 score 基本都在 0 到 1 之间；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"现有的表示主要存在的问题：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"classification score 和 IoU / centerness score 训练测试不一致，具体有：\n用法不一致。训练的时候，分类和质量估计是分开训练的，但是在测试的时候又是乘在一起作为 NMS score 排序的依据；\n对象不一致。质量估计通常只针对正样本训练，对于 one-stage 检测器而言，在做 NMS score 排序的时候，所有的样本都会将分类 score 和质量预测 score 相乘用于排序，这样会引发一个情况：一个分类 score 相对低的真正负样本，由于预测了一个不可信的高质量 score，导致到它可能排到一个分类 score 不高并且质量 score 较低的真正的正样本的前面；\nBounding Box 回归采用的表示不够灵活，没有办法建模复杂场景下的 uncertainty；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Focal Loss 支持 0 或者 1 类型的离散 label，而对于分类 - 质量联合表示，label 是 0～1 之间的连续值。如果对 Focal Loss 在连续 label 上进行拓展，就可以使其即保证平衡正负难易样本的特性，又支持连续数值的监督，因此得到 Quality Focal Loss（QFL），具体形式如下：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textQFL(sigma)=-y-sigma^betaleft((1-y)log(1-sigma)+ylog(sigma) right)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 y 为 0～1 的质量标签，sigma 为预测，QFL 的全局最小解是 sigma=y。之后又增加了一个称为 Distribution Focal Loss（DFL）的 loss，目的是希望网络能够快速地聚焦到标注位置附近的数值，使得它们概率尽可能大，DFL 的具体形式如下：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"textDFL(S_iS_i+1)=-left((y_i+1-y)log(S_i)+(y-y_ilog(S_i+1)) right)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"如果将 QFL 和 DFL 统一起来，就可以表示为 GFL。","category":"page"},{"location":"AI/CV/#人脸识别","page":"-","title":"人脸识别","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"人脸识别中的模型 ArcFace……","category":"page"},{"location":"AI/CV/#SphereFace","page":"-","title":"SphereFace","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"推荐阅读：人脸识别合集｜8 SphereFace 解析，作者：Mengcius：这篇文章写得十分好，十分详细地介绍了 SphereFace 以及介绍了 Softmax Loss 的进化路线。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"SphereFace（超球面），是佐治亚理工学院 Weiyang Liu 等在 CVPR 2017 年的论文 SphereFace: Deep Hypersphere Embedding for Face Recognition. 提出了将 Softmax Loss 从欧几里得距离转换到角度间隔，增加决策余量 m，限制 W=1 和 b=0. ","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"主要思想：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"开集人脸识别（Open-set face recognition）：通常，人脸识别可分为人脸识别和人脸验证。前者将一个人脸分类为一个特定的标识，而后者确定一对图片是否属于同一人。闭集（open-set）是测试图像在训练集中可能出现过；开集（close-set）是测试图像没有在训练集中出现过。开集人脸识别比闭集人脸识别需要更强的泛化能力。过拟合会降低性能。\n闭集的人脸识别：相当于分类问题，学习可分离的特征就可以了，人脸验证或识别时提取出标签。所有测试标识都在训练集中预先定义。很自然地将测试人脸图像分类为给定的身份。在这种情况下，人脸验证相当于分别对一对人脸图像进行识别。\n开集的人脸识别：测试集通常与训练集分离，因为不可能将所有人脸图像归纳在一个训练集中，我们需要将人脸映射到一个可辨别的本地特征空间。在这种情况下，人脸识别被视为在输入人脸图片和数据库中的每个身份之间执行人脸验证。它是度量学习问题，关键是学习有判别力的大间隔特征（discriminative large-margin features），人脸验证或识别时都要比较特征间的距离。\nOpen-set FR 对特征要求的准则：在特定的度量空间内， 需要类内的最大距离小于类间的最小距离。\nA-Softmax Loss (Angular Softmax Loss)：使得 CNN 能够学习角度识别特征，引入了角度间隔 m，以使人脸特征的最大类内距离要小于最小类间距离，使学习的特征将更具有判别力；\nL-Softmax Loss、A-Softmax Loss、CosFace、ArcFace、COCO Loss、Angular Triplet Loss等都是 angular margin learning 系列；\n预处理（人脸对齐）：人脸关键点由 MTCNN 检测，再通过相似变换得到了被裁剪的对齐人脸。RGB 图像中的每个像素范围在 [0, 255]，通过减去 127.5 然后除以 128 进行标准化；\n训练（人脸分类器）：CNN + A-Softmax Loss，CNN 使用 ResNet 中的残差单元；\nCNN 框架与传统的方法相同，可以兼容不同的网络架构（VGG/GoogLeNet/ResNet 等）；\n使用 m=4 的 Angular Softmax Loss，使得学习的特征更具有判别力；\n测试：\n从人脸分类器 FC1 层的输出中提取表示特征 SphereFace，拼接了原始人脸特征和其水平翻转特征获得测试人脸的最终表示；\n对输入的两个特征计算余弦距离（Cosine Similarity），得到角度度量（Angular Metric）；\n人脸验证：用阈值判断余弦距离；\n人脸识别：用最近邻分类器；\nLFW 上 99.42%，YTF 上 95.0%，训练集使用 CASIA-WebFace。2017 年在 MegaFace上 识别率在排名第一。","category":"page"},{"location":"AI/CV/#度量学习","page":"-","title":"度量学习","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"度量学习（metric learning）：旨在学习一个相似的距离函数。传统的度量学习常常会学习一个距离度量矩阵 A ，在给定的特征 x_1x_2 上距离度量为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"x_1 - x_2_A=sqrt(x_1 - x_2)^top A (x_1 - x_2)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"最近流行的深度度量学习通常使用神经网络自动学习具有可区分性的特征 x_1x_2，然后是简单的进行距离度量，如欧几里得距离。用于深度度量学习的最广泛的损失函数是对比损失和三元组损失，两者都对特征施加了欧几里得距离。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"不同算分的度量学习：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"DeepFace、DeepID：通过 SoftMax Loss 学习面部特征，但只具有可分离性而不具有明显的可判别性。\nDeepID2：结合了 Softmax Loss 和 Contrastive Loss 以增强特征的判别能力。但它们产生不同的特征分布，Softmax 损失会产生一个角度的特征分布，对比损失是在欧几里得空间学习到的特征分布，所以特征结合时可能不是一个自然的选择。\nFaceNet：使用 Triplet Loss 来监督嵌入学习。但它需要非常大量数据（2 亿张人脸图像），计算成本很高。对比损失和三元组损失都不能限制在单个样本上，因此需要精心设计的双/三重挖掘过程，这既耗时又对性能敏感。\nVGGFace：先训练 CNN+Softmax Loss，再用 Triplet Loss 度量学习。\nA discriminative feature learning approach for deep face recognition. In ECCV2016：将 Softmax loss 与 Center loss 结合以增强特征的判别能力，但中心损失只起到缩小类间距离的作用，不具有增大类间距离的效果。\nL-Softmax Loss：作者和 A-Softmax Loss 是同一批人。L-Softmax Loss 也隐含了角度的概念。利用改进的 Softmax Loss 进行具有角度距离的度量学习。作为一种正则化方法，它在闭集分类问题上显示了很大的进步。A-Softmax Loss 简单讲就是在 Large-Margin Softmax Loss 的基础上添加了两个限制条件 W=1 归一化和 b=0，使得预测仅取决于 W 和 x 之间的角度。\n人脸识别的 DCNNs 有两个主要的研究方向：分类学习（对应 Softmax Loss）、度量学习（对应 Triplet Loss 等）。Contrastive Loss、Triplet Loss 等都将开集人脸识别问题视为度量学习问题，对比损失和三元组损失都是基于欧几里得距离的度量学习。","category":"page"},{"location":"AI/CV/#Softmax-Loss-的进化","page":"-","title":"Softmax Loss 的进化","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"Softmax 损失学习按角度分布的特征：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Softmax 损失可以自然地学习按角度分布的特征，如在训练集和测试集不同类别的特征只在角度上分离开，因此不会自然地促使包含任何欧几里德损失。\n从某种意义上说，基于欧几里德距离的损失与 Softmax 损失是不相容的，因此将这两种类型的损失结合起来并不是很好。\n学习特征时增大欧几里得距离，似乎是广泛认可的选择，但问题出现了：欧几里得距离是否总是适合于学习具有可判别性的面部特征？不适合，在 SphereFace 的文章中建议用角度距离代替。\n为什么用角度间隔？\n首先角度间隔直接与流形上的区别性联系在一起，流形上的区别性本质上与前面的一致，面也位于流形上。其次，由原始 Softmax Loss 获得的特征具有固有的角分布，将角度间隔与 Softmax Loss 结合起来实际上是更自然的选择。\n首先，它们只将欧几里得距离强加于学习到的特征，而我们的则直接考虑角度间隔。第二，contrastive loss、 triplet loss 在训练集中构成成对/三重集时都会受到数据扩展的影响，而我们的则不需要样本挖掘，并且对整个小批量都施加了可判别性约束（相比之下，对比损失和三重损失只会影响几个具有代表性的成对/三重集）。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"从一张图讲起：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"（1）原始 Softmax Loss","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"如图 a, b，x 为学习到的特征向量，W_i 和 b_i 是最后一个全连接层对应类 i 的权值和偏置。Softmax 计算两个类的概率为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"hatboldsymboly=textsoftmax(boldsymbolW^top boldsymbolx)=fracexp(boldsymbolW^top boldsymbolx+boldsymbolb)boldsymbol1^top_Cexp(boldsymbolW^top boldsymbolx+boldsymbolb)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"如果以二分类为例：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"p_1=fracexp(W_1^top x + b_1)exp(W_1^top x + b_1) + exp(W_2^top x + b_2)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"p_2=fracexp(W_2^top x + b_2)exp(W_1^top x + b_1) + exp(W_2^top x + b_2)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Softmax 损失的让两个类别分开来的决策边界（Decision Boundary）是：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"(W_1 - W_2)x + b_1 - b_2 = 0","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"如果将 Softmax 重写成 W 和 x 的内积形式，就有了 cos 夹角：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"mathcalL_i=-logleft(fracexpleft(W_y_i^top x_i + b_y_iright)sum_j expleft(W_j^top x_i + b_jright)right)=-logleft( fracexp left(W_y_i  x_i cos(theta_y_ii) + b_y_i right)sum_j exp left( W_jx_icos(theta_j i) + b_j right) right)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"学习到的特征分布投射到一个球体上，就可以看到两类别间不能简单地通过角度分类。两类别是可以分离开的，但还是有一些误差，Softmax 只学习到了可分离的特征，但内聚性不好，判别性不够。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"（2）Modified Softmax Loss","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"如图 c, d，Modified softmax loss 能够直接优化角度，使 CNN 能够学习角度分布特征。为了实现角度决策边界，最终 FC 层的权重实际上是无用的。因此，首先对权重进行归一化并将偏置项归零（W_i=1 b_i=0），其公式为","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"mathcalL_textmodified=frac1Nsum_i-logleft( fracexp(x_icos(theta_y_i i))sum_j exp(x_icos(theta_j i)) right)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"后验概率为 p_1 = xcos(theta_1) p_2=x cos(theta_2)，决策边界变为","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"x(costheta_1 - costheta_2)=0","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"结果仅取决于 theta_1 和 theta_2. 这个改进的 Softmax Loss 可以学习带有角边界的特征，加强了角度可分性，但是这些特征还是没有判别性（discriminative）","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"（3）A-Softmax Loss","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"如图 e, f，进一步引入角度间隔（Angular Margin），让分类更加困难从而学习判别性。角度间隔更加大了，但分布的弧长变短了。A-Softmax loss（Angular Softmax Loss）针对不同的类别采用不同的决策边界（每个边界都比原边界更严格），从而产生角间隔。引入一个整数 m 来定量控制决策边界，二分类的类 1 和类 2 的决策边界分别变为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"从类别 1 正确分类，需要 cos(mtheta_1)cos(theta_2)，决策边界就是 cos(mtheta_1)=cos(theta_2)。从类别 2 则相反。\n从角度的观点来考虑，从标识 1 正确分类 x 需要 mtheta_1theta_2，而从标识 2 正确分类 x 则需要 mtheta_2theta_1。\n因为 m 是正整数，cos 函数在 0 到 pi 范围又是单调递减的，所以 mtheta_1 要小于 theta_2，m 值越大，theta_1 越聚合，则学习的难度也越大。因此通过这种方式定义损失会逼得模型学到类间距离更大的，类内距离更小的特征。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"x(cos(mtheta_1) - cos(theta_2)) = 0 text for class 1","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"x(cos(theta_1) - cos(mtheta_2)) = 0 text for class 2","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"A-Softmax Loss 公式是将改进的 Softmax Loss 中 theta 乘以系数 m 整数间隔值。即以乘法的方式惩罚深度特征与其相应权重之间的角度。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"mathcalL_textang = frac1Nsum_i-logleft( fracexp(x_icos(mtheta_y_ii))exp(x_icos(mtheta_y_ii))+sum_jneq y_iexp(x_icos(theta_ji)) right)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"上是中 theta 的范围是 0pim，为了摆脱这一限制，将 cos(mthetai) 推广到一个单调递减的角函数 psi(thetai). mge1 是控制角度间隔大小的整数，当 m=1 时它就是 Modified Softmax Loss。需要注意的是在每一次迭代中权重归一化为 1. A-Softmax Loss 的最终公式为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"mathcalL_textang=frac1Nsum_i-logleft(fracexp(x_ipsi(theta_y_ii))exp(x_ipsi(theta_y_ii) + sum_jneq y_iexp(x_icos(theta_ji))) right)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 psi(theta_y_ii) = (-1)^kcos(mtheta_y_ii) - 2k theta_y_iiinfrackpimfrac(k+1)pim，且 kin0 m-1.","category":"page"},{"location":"AI/CV/#人脸识别中的损失函数","page":"-","title":"人脸识别中的损失函数","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"Softmax Loss：最常见的人脸识别函数，原理是去掉最后的分类层，作为解特征网络导出解特征向量用于人脸识别。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"hatboldsymboly=textsoftmax(boldsymbolW^top boldsymbolx)=fracexp(boldsymbolW^top boldsymbolx+boldsymbolb)boldsymbol1^top_Cexp(boldsymbolW^top boldsymbolx+boldsymbolb)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 boldsymbolW=boldsymbolw_1cdotsboldsymbolw_C 是由 C 个类的权重向量组成的矩阵，boldsymbol1^top_C 为 C 维的全 1 向量，hatboldsymbolyinmathbbR^C 为所有类别的预测条件概率组成的向量，第 c 维的值是第 c 类的预测条件概率。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"mathcalL_textsoftmax=-frac1N_bsum_i=1^N_blog fracexp(boldsymbolw_y_iboldsymbolx+b_y_i)boldsymbol1^top_Cexp(boldsymbolW^top boldsymbolx+boldsymbolb)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 boldsymbolw_y_i b_y_i 代表实际标签 y_i 对应的权重和偏置。softmax 在训练的时候收敛迅速，但是精确度一般达到 0.9 时就不会再上升。一方面作为分类网络，softmax 不能像 metric learning 一样显式地优化类间和类内距离，所以性能不会特别好；另外，人脸识别的关键在于得到泛化能力强的 feature，与分类能力并不是完全等价的。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"L-Softmax Loss：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"SphereFace（A-Softmax）：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Focal Loss：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Triplet Loss：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Triplet Loss 是在谷歌 2015 年的 FaceNet 论文中的提出来的，用于解决人脸识别相关的问题，原文为：《FaceNet: A Unified Embedding for Face Recognition and Clustering》。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Triplet 三元组指的是 anchor, negative, positive 三个部分，每一部分都是一个 embedding 向量，其中","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"anchor 指的是基准图片；\npositive 指的是与 anchor 同一分类下的一张图片；\nnegative 指的是与 anchor 不同分类的一张图片；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Triplet Loss 的目的是让 anchor 和 positive 的距离变得越来越小，而与 negative 的距离变得越来越大，损失函数定义如下：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"mathcalL=max(d(a p) - d(a n) + textmargin 0)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 a p n 分别代表 anchor，positive 和 negative。如果 negative example 很好识别时，anchor 与 negative 的距离会相对较大，即 d(an) 相比之下偏大，那么损失为 mathcalL=0；否则通过最小化损失函数，可以让 anchor 与 positive 的距离 d(ap) 更加接近 0，而与 negative 的距离 d(an) 更加接近给定的 margin。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"基于 triplet loss 的定义，可以将 triplet（三元组）分为三类：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"easy triplets（简单三元组）：triplet 对应的损失为 0 的三元组：d(an)d(ap) + textmargin；\nhard triplets（困难三元组）：negative example 与 anchor 距离小于 anchor 与 positive example 的距离，形式化定义为：d(an)d(ap)；\nsemi-hard triplets（一般三元组）：negative example 与 anchor 距离大于 anchor 与 positive example 的距离，但还不至于使得 mathcalLoss 为 0，即 d(ap)d(an)d(ap)+textmargin；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"PyTorch 实现：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"class TripletLoss(nn.Module):\n    \"\"\"Triplet loss with hard positive/negative mining.\n    \n    Reference:\n        Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n    \n    Imported from `<https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py>`_.\n    \n    Args:\n        margin (float, optional): margin for triplet. Default is 0.3.\n    \"\"\"\n    \n    def __init__(self, margin=0.3,global_feat, labels):\n        super(TripletLoss, self).__init__()\n        self.margin = margin\n        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n \n    def forward(self, inputs, targets):\n        \"\"\"\n        Args:\n            inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).\n            targets (torch.LongTensor): ground truth labels with shape (num_classes).\n        \"\"\"\n        n = inputs.size(0)\n        \n        # Compute pairwise distance, replace by the official when merged\n        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n        dist = dist + dist.t()\n        dist.addmm_(1, -2, inputs, inputs.t())\n        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n        \n        # For each anchor, find the hardest positive and negative\n        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n        dist_ap, dist_an = [], []\n        for i in range(n):\n            dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))\n            dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))\n        dist_ap = torch.cat(dist_ap)\n        dist_an = torch.cat(dist_an)\n        \n        # Compute ranking hinge loss\n        y = torch.ones_like(dist_an)\n        return self.ranking_loss(dist_an, dist_ap, y)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Center Loss：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"在 Triplet Loss 之后又提出了一个 Center Loss。Triplet 学习的是样本间的相对距离，没有学习绝对距离，尽管考虑了类间的离散性，但没有考虑类内的紧凑性。Center Loss 希望可以通过学习每个类的类中心，使得类内的距离变得更加紧凑，其公式如下：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"mathcalL_C=frac12sum_i=1^m x_i -c_y_i _2^2","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"其中 c_y_iinmathbbR^d 表示深度特征的第 y_i 类中心。理想情况下，c_y_i 应该随着深度特性的变化而更新。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"训练时：第一是基于mini-batch执行更新。在每次迭代中，计算中心的方法是平均相应类的特征（一些中心可能不会更新）。第二，避免大扰动引起的误标记样本，用一个标量 alpha 控制中心的学习速率，一般这个 alpha 很小（如 0.005）。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"计算 mathcalL_C 相对于 x_i 的梯度和 c_y_i 的更新方程为：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"fracpartial mathcalL_Cpartial x_i=x_i-c_y_i","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"Delta c_j = fracsum_i=1^m delta(y_i=j)cdot(c_j-x_i)1+sum_i=1^m delta(y_i=j)","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"class CenterLoss(nn.Module):\n    \"\"\"Center loss.\n    Reference:\n    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n    Args:\n        num_classes (int): number of classes.\n        feat_dim (int): feature dimension.\n    \"\"\"\n \n    def __init__(self, num_classes=751, feat_dim=2048, use_gpu=True):\n        super(CenterLoss, self).__init__()\n        self.num_classes = num_classes\n        self.feat_dim = feat_dim\n        self.use_gpu = use_gpu\n \n        if self.use_gpu:\n            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n        else:\n            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n \n    def forward(self, x, labels):\n        \"\"\"\n        Args:\n            x: feature matrix with shape (batch_size, feat_dim).\n            labels: ground truth labels with shape (num_classes).\n        \"\"\"\n        assert x.size(0) == labels.size(0), \"features.size(0) is not equal to labels.size(0)\"\n \n        batch_size = x.size(0)\n        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n        distmat.addmm_(1, -2, x, self.centers.t())\n \n        classes = torch.arange(self.num_classes).long()\n        if self.use_gpu: classes = classes.cuda()\n        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n        print(mask)\n \n        dist = []\n        for i in range(batch_size):\n            print(mask[i])\n            value = distmat[i][mask[i]]\n            value = value.clamp(min=1e-12, max=1e+12)  # for numerical stability\n            dist.append(value)\n        dist = torch.cat(dist)\n        loss = dist.mean()\n        return loss","category":"page"},{"location":"AI/CV/#光学字符识别","page":"-","title":"光学字符识别","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"光学字符识别（Optical Character Recognition，OCR）：挖掘图像中的文本信息，需要对图像中的文字进行检测和识别。OCR 的确切定义是，将包含键入、印刷或场景文本的电子图像转换成机器编码文本的过程。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"OCR 算法通常分为两个基本模块，属于物体检测其中一个子类的文本检测以及文本识别。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"传统的文本检测：基于二值化的连通区域提取，基于最大极值稳定区域（Maximally Stable Extremal Regions，MSER），方向梯度直方图（Histogram of Oriented Gradient，HOG）可以提取特征；隐马尔可夫模型（Hidden Markov Model，HMM）对最终的词语进行预测。","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"文本检测框架的两种类型：","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"基于候选框：在通用物体检测的基础上，通过设置更多不同长宽比的锚框来适应文本变长的特性，以达到文本定位的效果。类似的模型包括：Rosetta、SegLink、TextBoxes++；\n基于像素分割：首先通过图像语义分割获得可能属于的文本区域的像素，之后通过像素点直接回归或者对文本像素的聚合得到最终的文本定位。类似的模型包括：TextSnake、SPCNet、MaskTextSpotter；\n不同方法的优缺点：\n基于候选框的文本检测对文本尺度本身不敏感，对小文本的检出率更高；但是对于倾斜角度较大的密集文本块，该方法很容易因为无法适应文本方向的剧烈变化以及对文本的包覆性不够紧密而检测失败。\n基于候选框的检测方法利用整体文本的粗粒度特征，而非像素级别的精细特征，因此其检测精度往往不如基于像素分割的文本检测。\n基于像素分割的文本检测往往具有更好的精确度，但是对于小尺度的文本，因为对应的文本像素过于稀疏，检出率通常不搞，除非以牺牲检测效率为代价对输入图像进行大尺度的放大。\n同时基于候选框和像素分割：将基于候选框的文本检测框架和基于像素分割的文本检测框架结合在一起，共享特征提取部分，并将像素分割的结果转换为候选框检测回归过程中的一种注意力机制，从而使文本检测的准确性和召回率都得到提高，例如云从科技公司提出的 Pixel-Anchor；","category":"page"},{"location":"AI/CV/","page":"-","title":"-","text":"检测文字所在位置（CTPN）和识别文本区域内容（CRNN）","category":"page"},{"location":"AI/CV/#EAST","page":"-","title":"EAST","text":"","category":"section"},{"location":"AI/CV/","page":"-","title":"-","text":"一种高效准确的场景文本检测器（An Efficient and Accurate Scene Text Detector，EAST）：","category":"page"},{"location":"AI/GNN/#通用框架","page":"-","title":"通用框架","text":"","category":"section"},{"location":"AI/GNN/","page":"-","title":"-","text":"除了图神经网络的不同变体，人们还提出了一些通用框架，旨在将不同的模型集成到单一的框架中。^1","category":"page"},{"location":"AI/GNN/#消息传递神经网络","page":"-","title":"消息传递神经网络","text":"","category":"section"},{"location":"AI/GNN/","page":"-","title":"-","text":"消息传递神经网络^2（MPNN, Message Passing Neural Network）包含两个阶段：消息传递阶段和读出阶段。\t","category":"page"},{"location":"AI/GNN/","page":"-","title":"-","text":"","category":"page"},{"location":"AI/GNN/","page":"-","title":"-","text":"参考：","category":"page"},{"location":"AI/GNN/","page":"-","title":"-","text":"[1] 刘知远，周界，《图神经网络导论》","category":"page"},{"location":"AI/GNN/","page":"-","title":"-","text":"[2]  J. Gilmmer, S. S. Schoenholz, P. F. Riley, et al. Neural message passing for quantum chemistry. In Proc. of ICML, 2018: 1263-1272. ","category":"page"},{"location":"AI/GNN/","page":"-","title":"-","text":"[3] 刘忠雨，李彦霖，周洋，《深入浅出图神经网络》","category":"page"},{"location":"AI/Transformer/#Transformer-知识总结","page":"-","title":"Transformer 知识总结","text":"","category":"section"},{"location":"AI/Transformer/#原理","page":"-","title":"原理","text":"","category":"section"},{"location":"AI/Transformer/","page":"-","title":"-","text":"Transformer 整个网络结构由 Attention 机制组成。在 RNN（包括 LSTM、GRU 等）中计算是顺序的，只能从左向右或者从右向左依次计算，这种机制带来的 2 个问题：","category":"page"},{"location":"AI/Transformer/","page":"-","title":"-","text":"时间片 t 的计算依赖 t-1 时刻的计算结果，限制了模型的并行能力；\n顺序计算的过程中信息会丢失。尽管 LSTM 使用门机制的结构来缓解长期依赖的问题，但是在特别长期时依旧表现不好；","category":"page"},{"location":"AI/Transformer/","page":"-","title":"-","text":"Transformer 通过以下方式来解决上面的问题：","category":"page"},{"location":"AI/Transformer/","page":"-","title":"-","text":"使用 Attention 机制，讲序列中的任意两个位置之间的距离缩小为一个常量；\n因为不是类似 RNN 的顺序结构，因此具有更好的并行性。也更为符合现有的 GPU 框架；","category":"page"},{"location":"AI/Transformer/#Encoder-和-Decoder-模块","page":"-","title":"Encoder 和 Decoder 模块","text":"","category":"section"},{"location":"AI/Transformer/","page":"-","title":"-","text":"Encoder 模块将 Backbone 输出的 feature map 转换成一维表征，然后结合 positional encoding 作为 Encoder 的输入。每个 Encoder 都由 Multi-Head Self-Attention 和 FFN 组成。和 Transformer Encoder 不同的是，因为 Encoder 具有位置不变性，DETR 将 positional encoding 添加到每一个 Multi-Head Self-Attention 中，来保证目标检测的位置敏感性。","category":"page"},{"location":"AI/Transformer/","page":"-","title":"-","text":"Decoder 也具有位置不变性，Decoder 的 n 个 object query（可以理解为学习不同 object 的 positional embedding）必须是不同的，以便产生不同的结果，并且同时把它们添加到每一个 Multi-Head Attention 中。n 个 object queries 通过 Decoder 转换成一个 output embedding，然后 output embedding 通过 FFN 独立解码出 n 个预测结果，包含 box 和 class。对输入 embedding 同时使用 Self-Attention 和 Encoder-Decoder Attention，模型可以利用目标的相互关系来进行全局推理。","category":"page"},{"location":"AI/Transformer/","page":"-","title":"-","text":"和 Transformer Decoder 不同的是，DETR 的每个 Decoder 并行输出 n 个对象，Transformer Decoder 使用的是自回归模型，串行输出 n 个对象，每次只能预测一个输出序列的一个元素。","category":"page"},{"location":"AI/Transformer/#多头注意力（Multi-Head-Attention）","page":"-","title":"多头注意力（Multi-Head Attention）","text":"","category":"section"},{"location":"AI/Transformer/","page":"-","title":"-","text":"多头注意力的提出是为了对同一 key、value、query，希望抽取不同的信息，例如短距离和长距离，类似于 CV 中的感受野（field）。","category":"page"},{"location":"AI/Transformer/#参考","page":"-","title":"参考","text":"","category":"section"},{"location":"AI/Transformer/","page":"-","title":"-","text":"[1] 知乎专栏：计算机视觉面试题 - Transformer 相关问题总结，作者：爱者之贻","category":"page"},{"location":"AI/DeepLearn/#逐层归一化","page":"-","title":"逐层归一化","text":"","category":"section"},{"location":"AI/DeepLearn/","page":"-","title":"-","text":"逐层归一化（Layer-wise Normalization）是将传统机器学习中的数据归一化应用到深度神经网络中，对神经网络中隐藏层的输入进行归一化，从而使得网络更容易训练。","category":"page"},{"location":"AI/DeepLearn/#批量归一化","page":"-","title":"批量归一化","text":"","category":"section"},{"location":"AI/DeepLearn/","page":"-","title":"-","text":"批量归一化（Batch Normalization, BN）中，如果 input batch 的 shape 为 (B, C, H, W)，统计出的 mean 和 variance 的 shape 为 (1, C, 1, 1). ","category":"page"},{"location":"AI/RNN/#快速索引目录","page":"-","title":"快速索引目录","text":"","category":"section"},{"location":"AI/RNN/#循环神经网络","page":"-","title":"循环神经网络","text":"","category":"section"},{"location":"AI/RNN/","page":"-","title":"-","text":"记录网络的输入序列为 x_1x_2cdotsx_n，一个循环神经网络（RNN）展开后可以看做一个 n 层的前馈神经网络，第 t 层对应着 t 时刻的状态（t=12cdotsn），记第 t 层（时刻）的输入状态、隐藏状态、输出状态分别为 x_t h_t o_t，训练时的目标输出值为 y_t，则有：隐藏状态 h_t 由当前时刻的输入状态 x_t 和上一时刻的隐藏状态 h_t-1 共同确定，即","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"h_t=sigma(Ux_t+Wh_t-1+b)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"其中，U 是输入层到隐藏层的权重矩阵，W 是不同时刻的隐藏层之间的连接权重，b 是偏置向量，sigma(cdot) 是激活函数（通常使用 textttTanh 函数）。循环神经网络最大的特点就是当前时刻的隐藏状态不仅与当前时刻的输入状态有关，还受上一时刻的隐藏状态影响。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"输出状态 o_t 的计算公式为：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"o_t=g(Vh_t+c)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"其中，V 是隐藏层到输出层的权重矩阵，c 是偏置向量，g(cdot) 是输出层的激活函数（对于分类任务可以采用 textttSoftmax 函数）。在训练时，网络在整个序列上的损失可以定义为不同时刻的损失之和：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"mathcalL=sum_tmathcalL_t=sum_t Loss(o_ty_t)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"上述的权重矩阵 U W V 是所有时刻共享参数的，这种机制不仅可以极大地减少网络需要学习的参数数量，而且使得网络可以处理长度不固定的输入序列。在 RNN 的训练过程中，由于不同时刻的状态是相互依赖的，因此需要存储各个时刻的状态信息，而且无法进行并行计算，这导致整个训练过程内存消耗大，并且速度较慢。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"RNN 之所以能够在序列数据的处理上获得出色的表现，是因为它拥有长期记忆功能，能够压缩并获得长期数据的表示。实际上，在 RNN 训练过程中，为了防止梯度爆炸（或弥散）的问题，通常采用带截断的反向传播算法，即仅反向传播 k 个时间步的梯度。理论上的无限记忆优势在实际中几乎不存在。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"实际上，在序列任务中，卷积神经网络（CNN）在空洞卷积的帮助下（例如 TextCNN），具有更好的并行化和可训练性。只不过长短期记忆网络（LSTM）和 Seq2Seq 网络依然是序列数据处理中最为通用的架构。还有人很多工作对卷积神经网络和循环神经网络进行组合使用，提升序列数据处理能力（如 TrellisNet）。","category":"page"},{"location":"AI/RNN/#随时间反向传播算法（BPTT）","page":"-","title":"随时间反向传播算法（BPTT）","text":"","category":"section"},{"location":"AI/RNN/","page":"-","title":"-","text":"随时间反向传播算法（BackPropagation Through Time, BPTT）将 RNN 看做一个展开的多层前馈网络，每一层对应 RNN 中的每个时刻。在展开的前馈网络中，所有层的参数是共享的，因此参数的真实梯度是所有展开层的参数梯度之和。","category":"page"},{"location":"AI/RNN/#长短期记忆网络（LSTM）","page":"-","title":"长短期记忆网络（LSTM）","text":"","category":"section"},{"location":"AI/RNN/","page":"-","title":"-","text":"LSTM 在标准 RNN 基础上做了改进，解决 RNN 训练过程中的梯度消失问题。增加了控制门单元：遗忘门、输入门、输出门，这些门控单元组合成 cell 状态，可以保证 LSTM 在长序列场景下的信息保持。","category":"page"},{"location":"AI/RNN/#长程依赖问题","page":"-","title":"长程依赖问题","text":"","category":"section"},{"location":"AI/RNN/","page":"-","title":"-","text":"LSTM 是如何实现长短期记忆功能的？","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（1）一般的 RNN 中，只有一个隐藏状态（hidden state）单元 h_t，不同时刻隐藏状态单元的参数是相同（共享）的。LSTM 在普通 RNN 的基础上增加了一个元胞状态（cell state）单元 c_t，其在不同时刻有着可变的连接权重，可解决普通循环神经网络中的梯度消失或爆炸问题。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（2）LSTM 引入了门控单元，是神经网络学习到的用于控制信号的存储、利用和舍弃的单元。对于每一个时刻 t，LSTM 有输入门 i_t、遗忘门 f_i 和输出门 o_t 共 3 个门控单元。每个门控单元的输入包括当前时刻的序列信息 x_t 和上一时刻的隐藏状态单元 h_t-1，具体公式：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"i_t=sigmaleft( W_i x_t + U_i h_t-1 + b_i right)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"f_t=sigmaleft( W_f x_t + U_f h_t-1 + b_f right)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"o_t=sigmaleft( W_o x_t + U_o h_t-1 + b_o right)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"3 个门控单元都相当于一个全连接层，激活函数 sigma(cdot) 的取值范围是 0 1，常用 textttSigmoid 作为激活函数。当门控单元的状态为 0 时，信号会被全部丢弃；当状态为 1 时，信号会被全部保留。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（3）元胞状态单元从上一个时刻 c_t-1 到当前时刻 c_t 的转移是由输入门和遗忘门共同控制的。输入门决定了当前时刻输入信息 tildec_t 有多少被吸收，遗忘门决定了上一时刻元胞状态单元 c_t-1 有多少不被遗忘，最终的元胞状态单元 c_t 由两个门控处理后的信号取和产生。具体公式：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"tildec_t = textttTanhleft( W_c x_t + U_c h_t-1 + b_c right)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"c_t = f_t odot c_t-1 + i_t odot tildec_t","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"其中 odot 为逐元素点乘操作。LSTM 的隐藏状态单元 h_t 则由输出门 c_t 决定：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"h_t = o_t odot textttTanh(c_t)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"不仅隐藏状态单元 h_t-1 和 h_t 之间有着较为复杂的循环连接，内部的元胞状态单元 c_t-1 和 c_t 之间还具有线性自循环关系，这个关系可以看作是在滑动处理不同时刻的信息。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（4）LSTM 中遗忘门和输出门的激活函数十分重要。删除遗忘门的激活函数会导致之前的元胞状态不能很好地被抑制；而删除输出门的激活函数则可能会出现非常大的输出状态。","category":"page"},{"location":"AI/RNN/#门控循环单元（GRU）","page":"-","title":"门控循环单元（GRU）","text":"","category":"section"},{"location":"AI/RNN/","page":"-","title":"-","text":"（1）GRU 只有两个门控单元，分别为重置门 r_t 和 更新门 z_t，一个控制短期记忆，另一个控制长期记忆。重置门控制前一状态有多少信息被写入到当前的候选集上，其值越小，前一个状态的信息被写入的就越少；更新门用于控制前一个时刻的状态信息被代入到当前状态中的程度，其值越大，说明前一个时刻的状态信息带入越多。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（2）GRU 中每个门控单元的输入包括当前时刻和序列信息 x_t 和上一时刻的隐藏状态单元 h_t-1，具体计算公式为：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"r_t = sigmaleft( W_r x_t + U_r h_t-1 right)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"z_t = sigmaleft( W_z x_t + U_z h_t-1 right)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"其中 sigma(cdot) 是激活函数，一般用 textttSigmoid。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（3）GRU 中重置门决定先前的隐藏状态单元是否被忽略，而更新门则控制当前隐藏状态单元是否需要被新的隐藏状态单元更新，具体公式：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"tildeh_t = textttTanh left( W_h x_t + U_h (r_t odot h_t-1) right)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"h_t = (1 - z_t) h_t - 1 + z_t tildeh_t","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"其中，(1 - z_t)h_t-1 表示上一时刻保留下来（没被遗忘）的信息，z_t tildeh_t 是当前时刻记忆下来的信息。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"用 1 - z_t z_t  作为系数，表明对上一时刻遗忘多少权重的信息，就会在这一时刻记忆多少权重的信息以作为弥补。GRU 就是用这样的一种方式用一个更新门 z_t 实现遗忘和记忆两个功能。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（4）GRU 只有一个隐藏状态单元 h_t，而 LSTM 有隐藏状态单元 h_t 和元胞状态单元 c_t。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（5）GRU 具有更少的参数，更易于计算和实现。在不同数据集、不同超参配置下，可以取得与 LSTM 相当甚至更好的性能，并且具有更快地收敛速度。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"❓GRU 通过什么方法保留前面时序的信息？","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"❓GRU 使用什么损失函数？","category":"page"},{"location":"AI/RNN/#序列到序列（Seq2Seq）","page":"-","title":"序列到序列（Seq2Seq）","text":"","category":"section"},{"location":"AI/RNN/","page":"-","title":"-","text":"（1）Seq2Seq 的映射架构能够将一个可变长序列映射到另一个可变长序列。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（2）Seq2Seq 框架由于输入序列和输出序列是不等长的因此整个处理过程需要拆分为对序列的理解和翻译，也就是编码和解码。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（3）采用一个固定尺寸的状态向量 C 作为编码器与解码器之间的「桥梁」。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（4）假设输入序列为 X=(x_1x_2cdotsx_T)，编码器可以是一个简单的循环神经网络，其隐藏状态 h_t 的计算公式为：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"h_t = f(h_t-1 x_t)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"其中，f(cdot) 是非线性激活函数，可以是简单的 textttSigmoid 函数，也可以是复杂的门控函数（LSTM、GRU 等）。将上述循环神经网络（编码器）最后一个时刻的隐藏状态 h_T 作为状态向量，并输入到解码器。C 是一个尺寸固定的向量，并且包含了整个序列的所有信息。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（5）解码器需要根据固定尺寸的状态向量 C 来生成长度可变的解码序列 Y=(y_1 y_2 cdots y_T)。这里解码序列的长度 T^prime 和编码长度 T 可以是不同的。解码器也可以用一个简单的循环神经网络来实现，其隐藏状态 h_t 可以按照如下公式计算：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"h_t = f(h_t-1y_t-1C)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"解码器的输出由如下公式决定：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"P(y_tmid y_t-1y_t-2cdotsy_1C) = g(h_t y_t-1C)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"其中，g(cdot) 会产生一个概率分布（例如用 textttSoftmax 函数产生概率分布）。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（6）解码器的工作流程：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"首先在收到一个启动信号（如 y_0=text start gt）后开始工作，根据 h_t y_t-1 C 计算出 y_t  的概率分布；\n然后对 y_t 进行采样获得具体取值；\n循环上述操作，直到遇到结束信号（如 y_t=text eos gt；","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（7）解码器的实现还能够用一种更加简单的方式，仅在初始时刻需要状态向量 C，其他时刻仅接收隐藏状态和上一时刻的输出信息 P(y_t)=g(h_ty_t-1)。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（8）在训练时，需要让模型输出的序列尽可能正确，这可以通过最大化对数似然概率来实现：","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"max_theta frac1Nsum_n=1^N log p_theta(Y_n mid X_n)","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"其中 theta 为模型参数，X_n 是一个输入序列，Y_n 是对应的输出序列， (X_nY_n) 构成一个训练样本对。","category":"page"},{"location":"AI/RNN/","page":"-","title":"-","text":"（9）因为是序列到序列的转换，实际应用中可以通过贪心法求解 Seq2Seq，当度量标准、评估方式确定后，解码器每次根据当前的状态和已解码的序列选择一个最佳的解码结果，直至结束。","category":"page"},{"location":"AI/FE/#组合特征","page":"-","title":"组合特征","text":"","category":"section"},{"location":"AI/FE/","page":"-","title":"-","text":"为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。在实际问题中，需要面对多种高维特征，简单地两两组合，依然容易存在参数过多、过拟合等问题。","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"怎样有效地找到组合特征？ 可以利用决策树来寻找特征组合方式。","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"例如，影视推荐问题有两个低阶特征「语言」和「类型」，其中有语言分为中文和英文，类型分为电影和电视剧，那么这两个特征的高阶组合特征有（中文，电影）、（英文，电视剧）、（英文，电影）、（中文，电视剧）四种。下表的数据，就可以变为新的数据：","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"是否点击 语言 类型\n0 中文 电影\n1 英文 电影\n1 中文 电视剧\n0 英文 电视剧","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"是否点击 语言 = 中文，类型 = 电影 语言 = 英文，类型 = 电影 语言 = 中文，类型 = 电视剧 语言 = 英文，类型 = 电视剧\n0 1 0 0 0\n1 0 1 0 0\n1 0 0 0 1\n0 0 0 0 1","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"以逻辑回归为例，假设数据的特征向量为 X=(x_1x_2dotsx_k)，则有：","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"Y=textsigmoid(sum_isum_jw_ijlangle x_ix_jrangle)","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"其中 langle x_ix_jrangle 表示 x_i 和 x_j 的组合特征，w_ij 的维度等于第 i 和第 j 个特征不同取值的个数。在上例中，「语言」这个特征有中文和英文两个选择，「类型」这个特征有电影和电视剧两个选择，那么 w_ij 的维度就为 2times 2=4. 当组合之前的两个特征不同取值的个数都不大时，用这种方式不会有太大的问题。但是对于某些问题，有用户 ID 和物品 ID，而用户和物品的数量动辄几千万，几千万乘几千万 mtimes n，这么大的参数量，无法进行学习。","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"对于这种「高维组合特征」要如何处理？假设用户和物品的数量分别为 m 和 n，一种行之有效的方法是将两个特征分别用 k 维的低维向量表示（kll mkll n），这样原本 mtimes n 的学习参数就降低为 mtimes k + ntimes k，这其实等价于推荐算法中的矩阵分解。","category":"page"},{"location":"AI/FE/#文本表示模型","page":"-","title":"文本表示模型","text":"","category":"section"},{"location":"AI/FE/","page":"-","title":"-","text":"最基础的文本表示模型是词袋模型，就是将每篇文章看成一袋子词，并忽略每个词出现的顺序。每篇文章可以表示成一个长向量，向量中的每一维度代表一个单词，而该维对应的权重则反映了这个词在原文章中的重要程度。常用 TF-IDF（Term Frequency-Inverse Document Frequency）来计算权重：","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"textTF-IDF(td)=textTF(td)times textIDF(t)","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"其中 textTF(td) 为单词 t 在文档 d 中出现的频率，textIDF(t) 是逆文档频率，用来衡量单词 t 对表达语义所起的重要性，表示为：","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"textIDF(t) = logfractextNum of articlestextNum of articles containing word t+1","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"直观解释为，如果一个单词在非常多的文章里面都出现，那么它可能是一个比较通用的词汇，对于区分谋篇文章特殊语义的贡献比较小，因此对权重做一定惩罚。","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"有的时候，多个不同的单词组合起来会有特殊的含义，比如 natural language processing 组合起来就有「自然语言处理」的意思，但是把这三个单词拆开，就没有组合起来的特别。将类似这样的连续出现的 n 个词（nle N）组成的词组（N-gram）也作为一个单独的特征放到向量表示中去，构成 N-gram 模型。","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"词干抽取（Word Stemming），同一个词可能有多种词性变化，却有相似的含义。在实际应用中，一般会对单词进行词干抽取，即将不同词性的单词统一成为同一词干的形式。","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"主题模型用于从文本库中发现有代表性的主题（得到每个主题上面词的分布特性）。","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"词嵌入是一类将词向量化的模型的统称，将每个词都映射成低维空间上的一个稠密向量（Dense Vector），通常维度 K=50sim 300。词嵌入将每个词映射成一个 K 维向量，如果一篇文章有 N 个词，就可以用一个 Ntimes K 的矩阵来表示这篇文章。但是这样的表示仅仅只是底层的表示，在实际应用中，如果仅仅把这个矩阵作为原文本的表示特征输入到机器学习模型当中，很难得到令人满意的结果。","category":"page"},{"location":"AI/FE/#Word2Vec","page":"-","title":"Word2Vec","text":"","category":"section"},{"location":"AI/FE/","page":"-","title":"-","text":"❓cbow 的原理是什么？","category":"page"},{"location":"AI/FE/","page":"-","title":"-","text":"❓cbow 和 skip-gram 的区别是什么？","category":"page"},{"location":"AI/RS/#大规模分段线性模型（LS-PLM）","page":"-","title":"大规模分段线性模型（LS-PLM）","text":"","category":"section"},{"location":"AI/RS/","page":"-","title":"-","text":"早在 2012 年，大规模分段线性模型（Large Scale Piece-wise Linear Model）就是阿里巴巴的主流推荐模型，又被称为混合逻辑回归（Mixed Logistics Regression），可以看作在逻辑回归的基础上采用分而治之的思路，先对样本进行分片，再在样本分片中应用逻辑回归进行 CTR（Click Through Rate，点击率）预估。","category":"page"},{"location":"AI/RS/#Embedding-技术","page":"-","title":"Embedding 技术","text":"","category":"section"},{"location":"AI/RS/","page":"-","title":"-","text":"Embedding，中文译为「嵌入」，常被翻译为「向量化」或者「向量映射」。形式上讲，Embedding 就是用一个低维稠密的向量「表示」一个对象，可以是词、商品、电影。","category":"page"},{"location":"AI/RS/#搜索相关性","page":"-","title":"搜索相关性","text":"","category":"section"},{"location":"AI/RS/","page":"-","title":"-","text":"搜索相关性旨在计算 Query 和返回 Doc 之间的相关程度，也就是判断 Doc 中的内容是否满足用户 Query 的需求，对应 NLP 中的语义匹配任务（Semantic Maching）。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"早期文本匹配：仅仅考虑 Query 与 Doc 的字面匹配程度，通过 TF-IDF、BM25 等基于 Term 的匹配特性来计算相关性。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"优点：线上计算效率高\n缺点：（1）基于 Term 的关键词匹配泛化性能较差，缺少语义和词序信息；（2）无法处理一词多义或多词一义的问题，漏匹配和误匹配现象严重。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"传统语义匹配模型：主要包括（1）隐式空间的匹配：将 Query 和 Doc 都映射到同一个空间的向量，再用向量距离或相似度作为匹配分，如 Partial Least Square (PLS)；（2）基于翻译模型的匹配：将 Doc 映射到 Query 空间后进行匹配或计算 Doc 翻译成 Query 的概率。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"深度语义匹配模型：实现方法上分为基于表示（Representation-based）和基于交互（Interaction-based）的方法。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"(Image: )","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"基于表示的深度语义匹配模型：分别学习 Query 和 Doc 的语义向量表示，再基于两个向量计算相似度。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"DSSM 模型 [微软]：提出经典的双塔结构的文本匹配模型，分别使用相互独立的两个网络结构构建 Query 和 Doc 的向量表示，用余弦相似度衡量两个向量的相关程度。\nNRM [微软 Bing 搜索]：针对 Doc 表征问题，除了基础的 Doc 标题和内容，还考虑了其他多源信息（每类信息称为一个域 Field），如外链、用户点击过的 Query 等，考虑一个 Doc 中有多个 Field，每个 Field 内又有多个实例（Instance），每个 Instance 对应一个文本，如一个 Query 词。模型首先学习 Instance 向量，将所有 Instance 的表示向量聚合起来就得到一个 Field 的表示向量，将多个 Field 的表示向量聚合起来得到最终 Doc 的向量。\nSentenceBERT：将预训练模型 BERT 引入到双塔的 Query 和 Doc 的编码层，采用不同的 Pooling 方式获取双塔的句向量，通过点乘、拼接等方式对 Query 和 Doc 进行交互。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"基于交互的深度语义匹配模型：不直接学习 Query 和 Doc 的语义表示向量，而是在底层输入阶段就让 Query 和 Doc 进行交互，建立一些基础的匹配信号，再将基础匹配信号融合成一个匹配分。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"ESIM：是预训练模型引入之前被业界广泛使用的经典模型，首先对 Query 和 Doc 进行编码得到初始向量，再用 Attention 机制进行交互加权后与初始向量进行拼接，最终分类得到相关性得分。引入预训练模型 BERT 进行交互计算时，通常将 Query 和 Doc 拼接作为 BERT 句间关系任务的输入，通过 MLP 网络得到最终的相关性得分。\nCEDR：在 BERT 句间关系任务获得 Query 和 Doc 向量之后，对 Query 和 Doc 向量进行拆分，进一步计算 Query 与 Doc 的余弦相似矩阵。","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"参考","category":"page"},{"location":"AI/RS/","page":"-","title":"-","text":"[1] 王喆，《深度学习推荐系统》2020","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"多模态数据：文本、图像、音频、视频、结构化数据","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"自然语言处理发展的三个阶段：","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"1950 ～ 1970 年：基于经验、规则的阶段；\n1970 ～ 2008 年：基于统计方法的阶段；\n2008 年至今：基于深度学习技术的阶段；","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"贝叶斯模型","category":"page"},{"location":"AI/NLP/#词袋模型","page":"-","title":"词袋模型","text":"","category":"section"},{"location":"AI/NLP/","page":"-","title":"-","text":"词袋模型（Bag-of-words, BOW）：假设词与词之间是上下文独立的，即不考虑词之间的上下文关系；","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"优点：\n简单易用速度快；\n在丢失一定预测精度的前提下，很好地通过词出现的频率来表征整个语句的信息；\n缺点：仅考虑词在一个句子中是否出现，而不考虑词本身在句子中的重要性（使用 TF-IDF 可以考虑重要性）；","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"对于两个语句：","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"\"We have noticed a new sign in to your Zoho account.\"\n\"We have sent back permission.\"","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"构造语料字典：","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"{\n    'We': 2, 'have': 2, 'noticed': 1, 'a': 1,\n    'new': 1, 'sign': 1, 'in': 1, 'to': 1,\n    'your': 1, 'Zoho': 1, 'account': 1, 'sent': 1,\n    'back': 1, 'permission.': 1\n}\n# 上面两个语句生成的 BOW 特征分别为：\n[1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"TF-IDF（Term Frequency-Inverse Document Frequency）：使用 textTFtimes textIDF 对每一个出现的词进行加权：","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"textTF-IDF(td)=textTF(td)times textIDF(t)","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"其中 textTF(td) 为单词 t 在文档 d 中出现的频率，textIDF(t) 是逆文档频率，用来衡量单词 t 对表达语义所起的重要性，表示为：","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"textIDF(t) = logfractextNum of articlestextNum of articles containing word t+1","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"直观解释为，如果一个单词在非常多的文章里面都出现，那么它可能是一个比较通用的词汇，对于区分谋篇文章特殊语义的贡献比较小，因此对权重做一定惩罚。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"优点：简单易用速度快；\n缺点：文本语料稀少、字典大小大于文本语料大小时，容易发生过拟合；","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"N-Gram 语言模型：假设有一个句子 S(w_1w_2w_3cdotsw_n)，其中 w_i 代表句子中的词，那么这个句子的出现概率就是所以单词出现概率的乘积 p(S)=p(w_1)times p(w_2)times p(w_3)timescdotstimes p(w_n). 在此基础上加上马尔科夫假设，即当前词的出现之和前 n 个词有关，则有：","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"p(S) = p(w_1)times p(w_2mid w_1)timescdots times p(w_nmid w_n-1)","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"N-Gram 模型可以与 BOW、TF-IDF 模型相结合，构建 Bi-Gram、Tri-Gram 等生成额外的稀疏特征向量，构建出来的特征比使用 Uni-Gram 的 BOW、TF-IDF 特征更具有表征能力。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"词袋模型的问题：如果近义词出现在不同文本中，那么在计算这一类文本的相似度或者进行预测时，如果训练数据不含大量标注，就会出现无法识别拥有相似上下文语义词的情况；","category":"page"},{"location":"AI/NLP/#词嵌入模型","page":"-","title":"词嵌入模型","text":"","category":"section"},{"location":"AI/NLP/","page":"-","title":"-","text":"Word2Vec：常用的模型训练方式为 CBOW 和 Skip-Gram 两种算法。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"glove：","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"fastText：","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"针对中文词向量的预训练，有腾讯公开的 AI Lab 词向量。","category":"page"},{"location":"AI/NLP/#深度学习","page":"-","title":"深度学习","text":"","category":"section"},{"location":"AI/NLP/","page":"-","title":"-","text":"TextCNN：模型结构简单，训练和预测速度快，同时拥有比传统模型更高的精度。采用多尺度卷积来模拟 N-Gram 模型在文本上的操作，最终合并之后进行呢预测。适合短文本以及有明显端与结构的语料。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"DPCNN：从 ResNet 结构中借鉴了残差块（residual block）的理念，模拟 CV 任务中对于图像特征进行逐层提取的操作。相比较于 TextCNN 能够在文本结构复杂、语义丰富或者上下文依赖性强的文本上有更好的表现。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"LSTM 类模型：包括典型双向循环神经网络结构 LSTM、Bi-LSTM、Bi-GRU + Attention，LSTM 和 GRU 层具有非常好的时序拟合能力。Attention 机制对不同时间的状态值进行加权，能够进一步提升模型的预测能力，适合具有复杂语义上下文的文本。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"Attention 机制：从原理上分析，是一种对词在句子中的不同状态进行加权的操作，从最原始的加权平均，逐步发展到 Self-Attention。通过使用词的相似度矩阵进行计算，调整词在句子中对应的权重，从而允许将词的加权求和作为输出或者下一层的输入。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"现有的上下文相关的预训练模型包括：ELMo、GPT、BERT、BERT-wwm、ERNIE_1.0、XLNet、ERNIE_2.0、RoBERTa、ALBERT、ELECTRA","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"ELMo：是一个采用自回归语言模型方式训练的语言模型。自回归语言模型的本质是通过输入的文本序列，对下一个词进行预测，通过不断优化预测的准确率，使模型逐步学到上下文的语义关系。ELMo 的结构包括正向 LSTM 层和反向 LSTM 层，通过分别优化正向下一次词和反向下一个词达到更好的预测效果。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"GPT：将 Multi-Head Attention 和 Transformer 结构应用到了语言模型的预训练上，采用正向 Transformer 结构，去除了其中的解码器，同 ELMo 模型一样，采用自回归语言模型的方式进行训练。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"BERT：使用自编码器模式进行训练，模型结构中包含正向和反向 Transformer 结构。为了减少由双向 Transformer 结构和自编码器造成的信息溢出影响，BERT 在训练中引入了 MLM，防止 BERT 模型因双向 Self-Attention 而导致的过拟合。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"MLM（Masked Language Model，遮蔽语言模型）：预训练中 15% 的词条（token）会被遮蔽，对于这 15% 的词条，有 80% 的概率会使用 [MASK] 替换，10% 的概率随机替换，10% 的概率保持原样，这个替换策略在模型训练中起到正则作用。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"RoBERTa：是 Facebook 提出的模型，在 BERT 的基础上移除了 NSP（Next Sentence Prediction）机制，并且修改了 MLM 机制，调整了其参数。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"ERNIE：是百度提出的模型，在 BERT 的基础上优化了对中文数据的预训练，增加了三个层次的预训练：Basic-Level Masking（第一层）、Phrase-Level Masking（第二层）、Entity-Level Masking（第三层），分别从字、短语、实体三个层次上加入先验知识，提高模型在中文语料上的预测能力。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"RoBERTa-wwm：由哈工大讯飞联合实验室发布，并不是一个严格意义上的新模型，wwm（whole word mask）是一种训练策略。BERT 所用的 MLM 具有一定的随机性，会将原始词的 word pieces 遮蔽掉，而 wwm 策略中，相同词所属的 word pieces 被遮蔽之后，其同属其他部分也会一同被遮蔽，在保证词语完整性的同时又不影响其独立性。","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"卷积神经网络","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"循环神经网络","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"自注意力机制（Self-Attention ）","category":"page"},{"location":"AI/NLP/","page":"-","title":"-","text":"Transformer","category":"page"},{"location":"DL/CNN/#各种卷积方式","page":"卷积神经网络","title":"各种卷积方式","text":"","category":"section"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: Conv2D)","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"最基本的卷积，每个卷积核的大小为 [channel_size, kernel_size, kernel_size]，通过设定 sride 的大小可以缩小特征图的大小。在 PyTorch 上的实现如下：","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"nn.Conv2d(in_channels=in_channel,    # 输入特征的通道数\n          out_channels=out_channel,  # 输出特征的通道数\n          kernel_size=kernel_size,   # 卷积核窗口的大小\n          stride=stride,             # stride 设置为 1 特征图不变，设置为 2 特征图变为 1/2\n          padding=padding)           # 卷积时候在特征图外部补充零的大小\n","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: Conv3D)","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: GroupConv)","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: DepthWiseConv)","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: PointWiseConv)","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: DepthWiseSeparableConv)","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: TransposedConv)","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: TransposedConv)","category":"page"},{"location":"DL/CNN/#网络结构","page":"卷积神经网络","title":"网络结构","text":"","category":"section"},{"location":"DL/CNN/#ViT（Vision-Transformer）","page":"卷积神经网络","title":"ViT（Vision Transformer）","text":"","category":"section"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: ViT)","category":"page"},{"location":"DL/CNN/#基本原理","page":"卷积神经网络","title":"基本原理","text":"","category":"section"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"ViT 与 Transformer 的唯一区别就在于，ViT 多了一个将图片进行嵌入的操作，简单地将就是把图片想个办法转换成 Transformer 的输入形式。实现这一个部分的操作就是 Vision Patch Embedding。","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"Vision Patch Embedding 把图片均匀分成一个一个的 Patch，然后把每一个 Patch reshape 成一维，这样就可以进入一个线性层，最后把所有 Patch 经过线性层之后的输出，与 pos_embedding 拼接成一个矩阵，作为 Transformer Block 的输入。看懂了 Patch Embedding 就懂 ViT 了。","category":"page"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"Vision Patch  Embedding 的实现，其实就是一个卷积操作，其中 kernel_size 和 stride 都为 patch_size，完整的结构可以看上图。","category":"page"},{"location":"DL/CNN/#代码实现","page":"卷积神经网络","title":"代码实现","text":"","category":"section"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"import torch\nfrom torch import nn\n\n\nclass TransformerHead(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.ln = nn.LayerNorm(hidden_dim)\n\n    def forward(self, x):\n        x = self.ln(x)\n        return x\n\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, num_heads, hidden_dim, mlp_dim, dropout, attention_dropout):\n        super().__init__()\n        self.num_heads = num_heads\n\n        self.ln_1 = nn.LayerNorm(hidden_dim)\n        self.self_attention = nn.MultiheadAttention(hidden_dim, num_heads, dropout=attention_dropout, batch_first=True)\n        self.dropout = nn.Dropout(dropout)\n\n        self.ln_2 = nn.LayerNorm(hidden_dim)\n        self.mlp = nn.Sequential(\n            nn.Linear(hidden_dim, mlp_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(mlp_dim, hidden_dim),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, input):\n        x = self.ln_1(input)\n        x, _ = self.self_attention(x, x, x, need_weights=False)\n        x = self.dropout(x)\n        x = x + input\n\n        y = self.ln_1(x)\n        y = self.mlp(y)\n        return x + y\n\n\nclass VisionPatchEmbedded(nn.Module):\n    def __init__(self, image_size, hidden_dim, patch_size, dropout):\n        super().__init__()\n        self.image_size = image_size\n        self.patch_size = patch_size\n        self.hidden_dim = hidden_dim\n        self.conv_proj = nn.Conv2d(in_channels=3, out_channels=hidden_dim, kernel_size=patch_size, stride=patch_size)\n        self.class_token = nn.Parameter(torch.zeros(1, 1, hidden_dim))\n        self.seq_length = (image_size // patch_size) ** 2 + 1\n        self.pos_embedding = nn.Parameter(torch.empty(1, self.seq_length, self.hidden_dim).normal_(std=0.02))\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        batch_size, _, h, w = x.shape\n        n_h = h // self.patch_size\n        n_w = w // self.patch_size\n        x = self.conv_proj(x)\n        x = x.reshape(batch_size, self.hidden_dim, n_h * n_w)\n        x = x.permute(0, 2, 1)\n\n        batch_class_token = self.class_token.expand(batch_size, -1, -1)\n        x = torch.cat([batch_class_token, x], dim=1)\n        x = x + self.pos_embedding\n        x = self.dropout(x)\n        return x\n\n\nclass VisionTransformer(nn.Module):\n    def __init__(self, image_size, patch_size, num_layers, num_heads, hidden_dim, mlp_dim, attention_dropout, dropout):\n        super().__init__()\n        self.patch_embedded = VisionPatchEmbedded(image_size, hidden_dim, patch_size, dropout)\n        self.transformer_layers = nn.Sequential(\n            *[TransformerBlock(num_heads, hidden_dim, mlp_dim, dropout, attention_dropout) for _ in range(num_layers)])\n        self.head = TransformerHead(hidden_dim)\n\n    def forward(self, x):\n        x = self.patch_embedded(x)\n        x = self.transformer_layers(x)\n        x = self.head(x)\n        return x\n\n\nif __name__ == '__main__':\n    image = torch.randn((1, 3, 224, 224))\n    _, _, height, width = image.shape\n    image_size = height\n    model = VisionTransformer(image_size, patch_size=16, num_layers=12, num_heads=12, hidden_dim=768, mlp_dim=3072,\n                              attention_dropout=0.5, dropout=0.5)\n    output = model(image)\n    print(output.shape)\n","category":"page"},{"location":"DL/CNN/#经典网络","page":"卷积神经网络","title":"经典网络","text":"","category":"section"},{"location":"DL/CNN/#AlexNet","page":"卷积神经网络","title":"AlexNet","text":"","category":"section"},{"location":"DL/CNN/","page":"卷积神经网络","title":"卷积神经网络","text":"(Image: AlexNet)","category":"page"},{"location":"AI/ML/#特征工程","page":"-","title":"特征工程","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"❓问：为什么要对特征做归一化处理？","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"特征归一化、标准化，是数据预处理中的重要技术。特征间的单位（尺度）可能不同，变化范围也可能是不同的，在进行距离有关的计算时，尺度大的特征会起决定性的作用，而尺度小的特征可能会被忽略，为了消除特征间单位和尺度差异的影响，要对特征做归一化处理。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"❓问：「类别型特征」的编码方式有哪些？","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"序号编码（Ordinal Encoding）：通常用于处理类别间具有大小关系的数据，转换后依然保留相对的大小关系。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"独热编码（One-hot Encoding）：通常用于处理类别间不具有大小关系的特征。对于类别取值较多的情况下使用 One-hot Encoding 需要注意以下问题：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"使用稀疏向量来节省空间。\n配合特征选择来降低维度。高维度特征会带来几方面的问题：\n在 K 近邻算法中，高维度空间下两点之间的距离很难得到有效的衡量；\n在逻辑回归模型中，参数的数量会随着维度的增高而增加，容易引起过拟合的问题；\n通常只有部分维度是对分类、预测有帮助，因此可以考虑配合特征选择来降低维度；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"二进制编码（Binary Encoding）：先用序号编码给每个类别赋予一个类别 ID，然后将类别 ID 对应的二进制编码作为结果。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Helmert Contrast","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Sum Contrast","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Polynomial Contrast","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Backward Difference Contrast","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"❓问：什么是组合特征？如何处理高维组合特征？","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。在实际问题中，需要面对多种高维特征，简单地两两组合，依然容易存在参数过多、过拟合等问题。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"怎样有效地找到组合特征？可以利用决策树来寻找特征组合方式。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"对于这种「高维组合特征」要如何处理？假设用户和物品的数量分别为 m 和 n，一种行之有效的方法是将两个特征分别用 k 维的低维向量表示（kll mkll n），这样原本 mtimes n 的学习参数就降低为 mtimes k + ntimes k，这其实等价于推荐算法中的矩阵分解。","category":"page"},{"location":"AI/ML/#距离函数","page":"-","title":"距离函数","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"欧氏距离：欧几里得距离，就是平方和开根号。是最常用的一种距离度量，欧氏距离越小，两个向量的相似度越大；欧氏距离越大，两个向量的相似度越小。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"曼哈顿距离：x_1-x_2 + y_1-y_2","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"切比雪夫距离：max(x_1 x_2 y_1 y_2)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"❓问：什么是余弦相似度？为什么有些场景使用余弦相似度而不使用欧氏距离？","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"对于两个向量 A 和 B，其余弦相似度定义为 cos(AB)=fracABAB，即两个向量夹角的余弦，关注的是向量之间的角度关系，并不关心它们的绝对大小，余弦相似度依然符合「相同为 1，正交为 0，相反为 -1」的性质，其取值范围是 -1 1，欧氏距离衡量空间点的直线距离，余弦距离衡量点在空间的方向差异，欧氏距离体现数值上的绝对差异，余弦距离体现方向上的相对差异。","category":"page"},{"location":"AI/ML/#模型评估","page":"-","title":"模型评估","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"❓过拟合和欠拟合是啥？","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"过拟合：在训练集上表现很好，测试集上表现很差。过拟合会导致高 Variance；\n欠拟合：在训练集上表现很差。欠拟合会导致高 Bias；\n模型需要在 Bias 与 Variance 之间做出一个权衡；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"解决欠拟合的方法：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"增加新特征，可以考虑加入特征组合、高次特征来增大假设空间；\n尝试非线性模型，比如核 SVM、决策树、DNN 等模型；\n如果有正则项可以适当降低正则项参数；\nBoosting 方法往往会有较小的 Bias；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"解决过拟合的方法：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"交叉验证，通过交叉验证得到较优的模型参数；\n减少特征的数量：通过人工选择保留哪些特征或者模型选择算法来降低；\n正则化：降低模型参数的数量；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Holdout 检验","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"交叉检验","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"自助法（Bootstrap）：有放回地从 N 个样本中抽样 n 个样本。当样本规模比较小的时候，将样本集进行划分会让训练集进一步减小，这可能会影响模型训练效果。自助法是基于自助采样的检验方法。在 n 次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，将这些没有被抽出的样本作为验证集，进行模型验证，这就是自助法的验证过程。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"交并比（Intersection over Union，IoU）：交并比 IoU 衡量的是两个区域的重叠程度，是两个区域的交集比上并集。在目标检测任务重，如果模型输出的矩形框与人工标注的矩形框 IoU 值大于某个阈值（通常为 0.5）时，即认为模型输出正确。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"精准率与召回率（Precision & Recall）：在目标检测中，假设有一组图片，Precision 代表我们模型检测出来的目标有多少是真正的目标物体，Recall 就是所有真实的目标有多少比例被模型检测出来了。目标检测中的真正例（True Positive）、真负例（True Negative）、假正例（False Positive）、假负例（False Positive）的定义如下：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":" 实际为正 实际为负\n预测为正 TP FP\n预测为负 FN TN","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"对于这四个指标可以这样去理解，后面的 Positive 和 Negative 以预测的结果为主，因为我们关注的是模型的预测，如果模型的预测与实际的标注不一样，那么这个预测就是「假的」，比如预测为负那么就称为 Negative，但是实际为正，与预测的不一样，那么就是「假的」False，因此这个预测就是 False Negative，这是一个「假的正例」是「错误的正例」。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"精准率，就是在预测为正样本中实际为正样本的概率，也就是所有的 Positive 中 True Positive 的概率","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Precision = fracTPTP+FP","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"召回率，就是在实际为正样本中预测为正样本的概率，就是所有的实际标注为正样本的（TP + FN）预测为正样本的概率（TP）","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Recall = fracTPTP+FN","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"准确率，就是模型预测正确的（所有的 True：TP + TN）占全部的比例","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Accuracy = fracTP+TNTP+TN+FP+FN","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"平均精度（Average precision，AP）：是主流的目标检测模型评价指标，它的意思是不同召回率上的平均精度。我们希望训练好的模型 Precision 和 Recall 都越高越好，但是这两者之间有个矛盾，当 Recall 很小的时候 Precision 可能会很高，当 Recall 很大的时候，Precision 可能会很低。我们将不同 Recall 对应的 Precision 做一个曲线（PR 曲线），然后在这个曲线上计算 Precision 的均值。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"曲线下面积（Area Under Curve，AUC）：","category":"page"},{"location":"AI/ML/#优化算法","page":"-","title":"优化算法","text":"","category":"section"},{"location":"AI/ML/#损失函数总结","page":"-","title":"损失函数总结","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"为了刻画模型输出与样本标签的匹配程度，定义损失函数 L(cdotcdot)Ytimes Yrightarrow mathbbR_ge 0，L(f(x_itheta)y_i) 越小，表明模型在该样本点匹配得越好。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"为了具有更加简介的表达，将网络的输出表示为 f，而实际标签表达为 y。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"在分类问题上常用的损失函数：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（1）0-1 损失函数：最常用于二分类问题，Y=1-1，我们希望 textttsign f(x_itheta)=y_i，所以 0-1 损失函数为","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_0-1(fy) = 1_fyle 0","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 1_P 是指示函数（Indicator Function），当且仅当 P 为真时取值为 1，否则取值为 0。0-1 损失的优点是可以直观地刻画分类的错误率，缺点是由于其非凸、非光滑的特点，算法很难对该函数进行优化。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（2）Hinge 损失函数：是 0-1 损失函数相对紧的凸上界，且当 fyge 1 时，函数不对其做任何惩罚。它在 fy=1 处不可导，不能够用梯度下降法进行优化，而是用次梯度下降法（Subgradient Descent Method）。适用于 Maximum-Margin 分类，主要用于支持向量机（SVM）中，用来解间距最大化的问题。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_texthinge(fy)=max01-fy","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（3）感知损失函数（Perceptron Loss）：是 Hinge 损失函数的一个变种。Hinge 对判定边界附近的点（正确端）惩罚力度很高，但是 Perceptron 只要样本的判定类别正确就行，不管其判定边界的距离。它比 Hinge 更加简单，不是 Max-margin Boundary，所以模型的泛化能力没有 Hinge 强。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_textPerceptron=max(0 -f)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（4）Logistic 损失函数：是 0-1 损失函数的凸上界，该函数处处光滑，对所有的样本点都有所惩罚，因此对异常值相对更敏感一点。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_textlogistic(fy)=log_2(1+exp(-fy))","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（5）Log 对数损失函数：即对数似然损失（Log-likelihood Loss），它的标准形式","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_textlog(f(boldsymbolxtheta)y)=-log f_y(boldsymbolxtheta)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 f_y(boldsymbolxtheta) 可以看作真实类别 y 的似然函数。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（6）交叉熵（Cross Entropy）损失函数：对于两个概率分布，一般可以用交叉熵去衡量它们的差异。标签的真实分布 boldsymboly 和模型预测分布 f(boldsymbolxtheta) 之间的交叉熵为","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"mathcalL(f(boldsymbolxtheta)boldsymboly)=-boldsymboly^toplog f(boldsymbolxtheta)=-sum_c=1^Cy_clog f_c(boldsymbolxtheta)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"因为 boldsymboly 为 one-hot 向量，因此交叉熵可以写为","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"mathcalL(f(boldsymbolxtheta)boldsymboly)=-log f_y(boldsymbolxtheta)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 f(boldsymbolxtheta) 可以看作真实类别 y 的似然函数。因此交叉熵损失函数也就是负对数似然函数（Negative Log-Likelihood）。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"在回归问题中常用的损失函数：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（1）平方损失（Mean Squared Error）函数：在回归问题中最常用的损失函数。对于 Y=mathbbR，我们希望 f(x_itheta)approx y_i","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_textMSE(fy)=(f-y)^2","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（2）绝对损失（Mean Absolute Error）函数：当预测值距离真实值较远的时候，平方损失函数的惩罚力度大，也就是说它对于异常点比较敏感。如果说平方损失函数是在做均值回归的话，那么绝对损失函数就是在做中值回归，对于异常点更加鲁棒一点。只不过绝对损失函数在 f=y 处无法求导。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_textMAE(fy)=f-y","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（3）Huber 损失函数：也称为 Smooth L1 Loss， 综合考虑可导性和对异常点的鲁棒性。在 f-y 较小的时候为平方损失，比较大的时候为线性损失","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_textHuber(fy)=begincases(f-y)^2qquad f-yle delta 2deltaf-y-delta^2quadf-ydeltaendcases","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（4）Log-Cosh 损失函数：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（5）分位数损失函数：","category":"page"},{"location":"AI/ML/#随机梯度算法","page":"-","title":"随机梯度算法","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"随机梯度下降法本质上是采用迭代方式更新参数，每次迭代在当前位置的基础上，沿着某一方向迈一小步抵达下一位置，不断地重复这个步骤，它的更新公式为","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"theta_t+1=theta_t - eta g_t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 eta 是学习率。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"动量（Momentum）方法：类比中学物理知识，当前梯度就好比当前时刻受力产生的加速度，前一次步长 v_t-1 好比前一时刻的速度，当前步长 v_t 好比当前加速度共同作用的结果。这就好比小球有了惯性，而刻画惯性的物理量是动量。模型参数的迭代公式为：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"v_t = gamma v_t-1 + eta g_t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"theta_t+1 = theta_t - v_t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"在这里当前更新步长 v_t 直接依赖于前一次步长 v_t-1 和当前梯度 g_t，衰减系数 gamma 扮演了阻力的作用。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"AdaGrad 方法：在应用中，我们希望更新频率低的参数可以拥有较大的更新步幅，而更新频率高的参数的步幅可以减小，AdaGrad 方法采用「历史梯度平方和」来衡量不同参数的梯度的稀疏性，取值越小表明越稀疏。AdaGrad 借鉴了 mathscrl_2 正则化的思想，每次迭代时自适应地调整每个参数的学习率。这样的方式保证了不同的参数有具有自适应学习率。具体的更新公式表示为：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"在第 t 次迭代时，先计算每个参数梯度平方的累计值","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"G_t = sum_tau=1^t boldsymbolg_tau odot boldsymbolg_tau","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 odot 为按元素乘积，boldsymbolg_tauin mathbbR^theta 是第 tau 次迭代时的梯度。参数更新差值为","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Deltatheta_t=-fracetasqrtG_t+epsilonodotboldsymbolg_t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 alpha 是初始学习率，epsilon 是为了保持数值稳定性而设定的非常小的常数，一般取值为 e^-7sim e^-10。分母中求和的形式实现了退火过程，意味着随着时间推移，学习速率 fracetasqrtG_t+epsilon 越来越小，保证算法的最终收敛。在 AdaGrad 算法中，如果某个参数的偏导数积累比较大，其学习率相对较小；相反如果其偏导数积累较小，其学习率相对较大，但整体是随着迭代次数的增加，学习率逐渐变小。","category":"page"},{"location":"AI/ML/#Adam-算法","page":"-","title":"Adam 算法","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"Adam 算法的全称是自适应动量估计算法（Adaptive Moment Estimation Algorithm），它将惯性保持和自适应两个优点结合，可以看作是动量法和 RMSprop 算法（或者 AdaGrad 算法）的结合。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"它一方面记录梯度的一阶矩（First Moment）M_t，即过往梯度与当前梯度的平均，理解为「惯性」，是梯度 boldsymbolg_t 的指数加权平均。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"另一方面记录梯度的二阶矩（Second Moment）G_t，即过往梯度平方与当前梯度平方的平均，理解为「自适应部分」，是梯度 boldsymbolg_t^2 的指数加权平均。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"一阶矩可以理解为均值；二阶矩可以理解为未减去均值的方差","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"M_t = beta_1 M_t-1 + (1 - beta_1)boldsymbolg_t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"G_t = beta_2 G_t-1 + (1 - beta_2)boldsymbolg_todotboldsymbolg_t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 beta_1 和 beta_2 分别为两个移动平均的衰减率，通常取值为 beta_1 = 09, beta_2 = 099. ","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Adam 算法考虑了 M_t G_t 在零初始情况下的偏置矫正。假设 M_0=0 G_0=0，那么在迭代初期 M_t 和 G_t 的值会比真实的均值和方差要小，特别是当 beta_1 和 beta_2 都接近于 1 时，偏差会很大。具体来说，Adam 算法的更新公式为：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"hatM_t = fracM_t1 - beta_1^t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"hatG_t = fracG_t1 - beta_2^t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Deltatheta_t = -fracalphasqrthatG_t + epsilon hatM_t","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中学习率 alpha 通常设为 0.001，并且也可以进行衰减，比如 alpha_t=alpha_0sqrtt. ","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Adam 算法的物理意义：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"《百面机器学习》163 页","category":"page"},{"location":"AI/ML/#逐层归一化","page":"-","title":"逐层归一化","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"逐层归一化（Layer Normalization）是将传统机器学习中的数据归一化方法应用到深度神经网络中，对神经网络中隐藏的输入进行归一化，使得网络更容易训练。常用的逐层归一化方法有：批量归一化、层归一化、权重归一化和局部响应归一化。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"内部协变量偏移（Internal Covariate Shift）：当使用随机梯度下降来训练网络时，每次参数更新都会导致该神经层的输入分布发生改变，越高的层，其输入分布会改变得越明显。从机器学习角度来看，如果一个神经层的输入分布发生了改变，那么其参数需要重新学习。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"逐层归一化的能够提高训练效率的原因：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（1）更好的尺度不变性：把每个神经层的输入分布都归一化为标准正态分布，可以使得每个神经层对其输入具有更好的尺度不变性。不论低层的参数如何变化，高层的输入保持相对稳定。另外，尺度不变性可以使得我们更加高效地进行参数初始化以及超参选择。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（2）更平滑的优化地形：逐层归一化一方面可以使得大部分神经层的输入处于不饱和区域，从而让梯度变大，避免梯度消失问题；另一方面还可以使得神经网络的优化地形（Optimization Landscape）更加平滑，以及使梯度变得更加稳定，从而允许我们使用更大的学习率，并提高收敛速度。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"批量归一化（Batch Normalization，BN）方法 是一种有效的逐层归一化方法，可以对神经网络中任意的中间层进行归一化操作。假设神经网络第 l 层的净输入为 boldsymbolz^(l)，神经元输出为 boldsymbola^(l)，即","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"boldsymbola^(l) = f(boldsymbolz^(l))=fleft( boldsymbolWboldsymbola^(l) + boldsymbolb right)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 f(cdot) 是激活函数，boldsymbolW boldsymbolb 是神经网络的参数。为了提高优化效率，就要使得净输入 boldsymbolz^(l) 的分布一致，比如都归一化到标准正态分布。归一化操作一般应用在仿射变换（Affine Transformation）boldsymbolWboldsymbola^(l)+boldsymbolb 之后，激活函数之前。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"为了提高归一化效率，一般使用标准化将净输入 boldsymbolz^(l) 的每一维都归一化到标准正态分布","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"hatboldsymbolz^(l) = fracboldsymbolz^(l)-mathbbEboldsymbolz^(l)sqrttextvar(boldsymbolz^(l))+epsilon","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 mathbbEboldsymbolz^(l) 和 textvar(boldsymbolz^(l)) 是当前参数下 boldsymbolz^(l) 的每一维在整个训练集上的期望和方差。","category":"page"},{"location":"AI/ML/#决策树与集成学习","page":"-","title":"决策树与集成学习","text":"","category":"section"},{"location":"AI/ML/#决策树（Decision-Tree）","page":"-","title":"决策树（Decision Tree）","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"一颗决策树包含一个根结点、若干个内部结点和若干个叶结点；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"叶结点对应于决策结果，其他每个结点则对应于一个属性测试；\n每个结点包含的样本集合根据属性测试的结果被划分到子结点中；\n根结点包含样本全集；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"决策树的生成是一个递归过程，遵循「分治策略」（divide-and-conquer）。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"决策树基本算法中导致递归返回的三种情况：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"当前结点包含的样本全部属于同一个类别；\n当前属性集为空，或是所有样本在所有属性上取值相同，无法划分。在这种情况下，把当前结点标记为叶结点，并将其类别设定为该结点所含样本最多的类别。这相当于利用了当前结点的后验分布；\n当前结点包含的样本集合为空，不能划分。在这种情况下，同样把当前结点标记为叶结点，但将其类别设定为其父结点所含样本最多的类别；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"信息熵（Information Entropy）：是度量样本集合纯度最常用的一种指标。假定当前样本集合 D 中第 k 类样本所占的比例为 p_k (k=12dotsmathcalY)，则 D 的信息熵为：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"textEnt(D)=-sum_k=1^mathcalYp_klog_2p_k","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"如果 textEnt(D) 的值越小，则 D 的纯度越高，纯度越高说明包含的信息量越少。textEnt(D)in0log_2mathcalY.","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"注意：计算信息熵时约定，若 p=0，则 plog_2p=0，这与极限一致 lim_prightarrow 0^+plog p=0。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"信息增益（Information Gain）：一般而言，信息增益越大，表示用属性 a 来进行划分所获得的「纯度提升」越大。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"假定离散属性 a 有 V 个可能的取值 a^1 a^2dotsa^V，如果使用 a 来对样本集 D 进行划分，则会产生 V 个分支结点，其中第 v 个分支结点包含了 D 中所有在属性 a 上取值为 a^v 的样本，记为 D^v.","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"因此用属性 a 对样本集 D 进行划分所获得的信息增益为：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"textGain(D a)=textEnt(D)-sum_v=1^VfracD^vDtextEnt(D^v)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重 D^vD，表示样本数越多的分支结点的影响越大。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"著名的决策树算法 ID3（Iterative Dichotomiser，迭代二分器）就是以信息增益为准则来选择划分属性的。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"以信息增益作为准则来生成决策树有一个缺点，就是信息增益对可取值数目较多的属性有更大的偏好，一个更好的方法就是使用「增益率」（Gain Ratio）来选择最优划分属性，著名的 C4.5 决策树算法就利用增益率来生成决策树。增益率的定义为：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"textGain_ratio(D a)=fractextGain(D a)textIV(a)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"textIV(a)=-sum_v=1^VfracD^vDlog_2fracD^vD","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"称为属性 a 的「固有值」（intrinsic value），属性 a 的可能取值书目越多，V 就会越大，textIV(a) 的值通常就会越大。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"但是增益率准则带来的一个缺点又变成了对可取值数目较少的属于更加偏好，因此 C4.5 算法并不直接选择增益率最大的候选划分属性，它的具体做法是：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的属性作为「最优划分属性」。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"基尼指数（Gini index）：反映了从数据集 D 中随机抽取两个样本，其类别标记不一致的概率。因此 textGini(D) 越小，则数据集 D 的纯度越高。属性 a 的基尼指数定义为：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"textGini_index(D a)=sum_v=1^VfracD^vDtextGini(D^v)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"在候选属性集合 A 中，选择那个使得划分后基尼指数最小的属性作为划分属性。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"CART 决策树（Classification and Regression Tree）就是使用基尼指数来选择划分属性的。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"剪枝（pruning）是决策树学习算法对付「过拟合」的主要手段，基本策略有「预剪枝」（pre-pruning）和「后剪枝」（post-pruning）。","category":"page"},{"location":"AI/ML/#Boosting-与-Bagging","page":"-","title":"Boosting 与 Bagging","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"机器学习问题的两种策略：一种是研发人员尝试各种模型，选择其中表现最好的模型，做重点调参优化；另一种是将多个分类器的结果统一成一个最终的决策，其中每个单独的分类器称为基分类器，使用这类策略的机器学习方法统称为集成学习。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"集成学习分为 Boosting 和 Bagging 两种。Boosting 方法训练基分类器时采用串行方式，各个基分类器之间有依赖。它的基本思路是将基分类器层层叠加，每一层在训练的时候，对前一层基分类器分错的样本，给予更高的权重。测试时，根据各层分类器的结果的加权得到最终结果。Bagging 与 Boosting 的串行训练方式不同，Bagging 方法在训练过程中，各基分类器之间无强依赖，可以进行并行训练。最著名的算法之一就是基于决策树基分类器的随机森林（Random Forest）。Bagging 方法更像是一个集体决策的过程，每个个体都进行单独学习，在最终做决策时，每个个体单独做出判断，再通过投票的方式做出最后的集体决策。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"基分类器，有时候又被称为弱分类器。基分类器的错误，是偏差和方差两种错误之和。偏差主要是由于分类器的表达能力有限导致的系统性错误，表现在训练误差不收敛，方差是由于分类器对于样本分布过于敏感，导致在训练样本数较少时，产生过拟合。而 Boosting 方法通过逐步聚焦于基分类器分错的样本，减小集成分类器的偏差。Bagging 方法则是采取分而治之的策略，通过对训练样本多次采样，并分别训练出多个不同模型，然后做综合，来减小集成分类器的方差。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"最常用的基分类器是决策树：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"决策树可以较为方便地将样本的权重整合到训练过程当中，而不需要使用过采样的方法来调整样本权重；\n决策树的表达能力和泛化能力，可以通过调节树的层数来做折中；\n数据样本的扰动对于决策树的影响较大，因此不同子样本集合生成的决策树基分类器随机性较大，这样的「不稳定学习期」更适合作为基分类器。（在这个点上，神经网络也因为不稳定性而适合作为基分类器，可以通过调节神经元数量、连接方式、网络层数、初始权值等方式引入随机性）；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"集成学习的基本步骤。集成学习一般可以分为以下 3 个步骤：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（1）找到误差互相独立的基分类器；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（2）训练基分类器；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（3）合并基分类器的结果；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"合并基分类器的方法有 voting 和 stacking 两种，前者对应 Bagging 方法，后者对应 Boosting 方法。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"以 Adaboost 为例，其基分类器的训练和合并的基本步骤如下：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（1）确定基分类器：可以选择 ID3 决策树作为基分类器。虽然任何分类模型都可以作为基分类器，但树形模型由于结构简单且较为容易产生随机性所以比较常用。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（2）训练基分类器：假设训练集为 x_iy_ii=1dotsN，其中 y_iin-11，并且有 T 个基分类器，则可以按照如下过程来训练基分类器：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"初始化采样分布 D_1(i)=1N；\n令 t=12dotsT 循环：\n从训练集中，按照 D_t 分布，采样出子集 S_i=x_iy_ii=1dotsN；\n用 S_i 训练出基分类器 h_t；\n计算基分类器 h_t 的错误率：\nvarepsilon_t=fracsum_i=1^N_tIh_t(x_i)neq y_iD_i(x_i)N_t\n其中 Icdot 为判别函数；\n计算基分类器 h_t 权重 a_t=logfrac(1-varepsilon_t)varepsilon_t，这里可以看到错误率 varepsilon_t 越大，基分类器的权重 a_t 就越小；\n设置下一次采样：\nD_t+1=begincasesD_t(i) text or  fracD_t(i)(1-varepsilon_t)varepsilon_t  h_t(x_i)neq y_i\nfracD_t(i)varepsilon_t(1-varepsilon_t)  h_t(x_i)= y_iendcases","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（3）合并基分类器：给定一个未知样本 z，输出分类结果为加权投票的结果 textSign(sum_t=1^Th_t(z)a_t).","category":"page"},{"location":"AI/ML/#梯度提升决策树（GBDT）","page":"-","title":"梯度提升决策树（GBDT）","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"❓GBDR 和 RF 有什么区别？","category":"page"},{"location":"AI/ML/#XGBoost","page":"-","title":"XGBoost","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"XGBoost 是陈天奇等人开发的一个开源机器学习项目，高效地实现了 GBDT 算法并进行了算法和工程上的许多改进，被广泛应用在 Kaggle 竞赛以及其他许多机器学习竞赛中。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"XGBoost 本质上还是一个 GBDT（Gradient Boosting Decision Tree），只是把速度和效率发挥到极致，所以前面加上了 X（代表 Extreme）。原始的 GBDT 算法基于经验损失函数的负梯度来构造新的决策树，只是在决策树构建完成后再进行剪枝。XGBoost 在决策树构建阶段就加入了正则项，即","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_t=sum_i lleft(y_i F_t-1(x_i)+f_t(x_i)right)+Omega(f_t)","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 F_t-1(x_i) 表示现有的 t-1 棵树最优解，树结构的正则项定义为","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Omega(f_t)=gamma T+frac12lambdasum_j=1^Tw^2_j","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"其中 T 为叶子节点个数，w_j 表示第 j 个叶子节点的预测值。对该损失函数在 F_t-1 处进行二阶泰勒展开可以推导出","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"L_tapproxoversetsimL_t=sum_j=1^TleftG_jw_j+frac12(H_j+lambda)w^2_jright+gamma T","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"从所有的树结构中寻找最优的树结构是一个 NP-hard 问题，在实际中往往采用贪心法来构建出一个次优的树结构，基本思想是根据特定的准则选取最优的分裂。不同的决策树算法采用不同的准则，如 IC3 算法采用信息增益，C4.5 算法为了克服信息增益中容易偏向取值较多的特征而采用信息增益比，CART 算法使用基尼指数和平方误差，XGBoost 也有特定的准则来选取最优分裂。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"❓XGBoost 与 GBDT 有什么区别和联系？","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（1）GBDT 是机器学习算法，XGBoost 是该算法的工程实现；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（2）在使用 CART 作为基分类器时，XGBoost 显式地加入了正则项来控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（3）GBDT 在模型训练时只使用了代价函数的一阶导数信息，XGBoost 对代价函数进行二阶泰勒展开，可以同时使用一阶和二阶导数；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（4）传统的 GBDT 采用 CART 作为基分类器，XGBoost 支持多种类型的基分类器，比如线性分类器；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（5）传统的 GBDT 在每轮迭代时使用全部的数据，XGBoost 则采用了与随机森林相似的策略，支持对数据进行采样；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（6）传统的 GBDT 没有设计对缺失值进行处理，XGBoost 能够自动学习出缺失值的处理策略；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"❓XGBoost 如何实现并行化生成树？","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"XGBoost 的并行化：boosting 是一种串行结构，它的并行不是在 tree 粒度上的，而是在特征粒度上的并行。决策树学习最耗时的一个步骤就是对特征的值进行排序（为了确定最佳分割点）。XGBoost 训练之前，预先对数据进行排序，保存为 block 结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个 block 结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"XGBoost 的特点：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"传统的 GBDT 以 CART 作为基函数，而 XGBoost 相当于有 L1/L2 正则化项的分类或者回归\n传统的 GBDT 在优化的时候只用到一阶导数，XGBoost 对代价函数进行了二阶泰勒展开，同时用到一阶和二阶导数。并且 XGBoost 工具支持自定义代价函数，只要函数可以一阶和二阶求导；\nXGBoost 在代价函数里加入了正则项，控制模型复杂度。正则项里包含了树的叶节点个数、每个叶子节点上输出 score 的 L2 模的平方和。从 Bias-variance tradeoff 角度来讲，正则项降低了模型 variance，使学习出来的模型更加简单，防止过拟合，这也是 XGBoost 优于传统 GBDT 的一个特性。 剪枝是都有的，叶子节点输出 L2 平滑是新增的；\nshrinkage 缩减和 column subsampling。shrinkage 缩减：类似于学习速率，在每一步 tree boosting 之后增加了一个参数 n（权重），通过这种方式来减小每棵树的影响力，给后面的树提供空间去优化模型。column subsampling：列（特征）抽样，随机森林那边学习来的，防止过拟合的效果比传统的行抽样还好（行抽样功能也有），并且有利于后面提到的并行化处理算法；\nsplit finding algorithms（划分点查找算法），树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法 greedy algorithm 枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以 XGBoost 还提出了一种可并行的近似直方图算法（Weighted Quantile Sketch），用于高效地生成候选的分割点；\n对缺失值的处理。对于特征的值有缺失的样本，XGBoost 可以自动学习出它的分裂方向。 稀疏感知算法 Sparsity-aware Split Finding；\n内置交叉验证（Built-in Cross-Validation），XGBoost 可以在 boosting 过程的每次迭代中运行交叉验证，因此很容易在一次运行中获得准确的最佳 boosting 迭代次数；\nXGBoost 支持并行，提高计算速度；","category":"page"},{"location":"AI/ML/#LightGBM","page":"-","title":"LightGBM","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"LightGBM 是 XGBoost 的更高效实现，由微软发布。LightGBM 相比于 Xgboost，添加了很多新的方法来改进模型，包括：并行方案、基于梯度的单边检测（GOSS）、排他性特征捆绑等。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"LightGBM 的设计思路主要是两点：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"减小数据对内存的使用，保证单个机器在不牺牲速度的情况下，尽可能地用上更多的数据；\n减小通信的代价，提升多机并行时的效率，实现在计算上的线性加速。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"由此可见，LightGBM 的设计初衷就是提供一个快速高效、低内存占用、高准确度、支持并行和大规模数据处理的数据科学工具。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"LightGBM 并没有垂直的切分数据集，而是每个 worker 都有全量的训练数据，因此最优的特征分裂结果不需要传输到其他 worker 中，只需要将最优特征以及分裂点告诉其他 worker，worker 随后本地自己进行处理。处理过程如下：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"每个 worker 在基于局部的特征集合找到最优分裂特征；\nworker 间传输最优分裂信息，并得到全局最优分裂信息；\n每个 worker 基于全局最优分裂信息，在本地进行数据分裂，生成决策树；","category":"page"},{"location":"AI/ML/#其他知识","page":"-","title":"其他知识","text":"","category":"section"},{"location":"AI/ML/","page":"-","title":"-","text":"HMM：EM 算法、维特比算法、前向后向算法、极大似然估计","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"在 HMM 中，如果已知观察序列和产生观察序列的状态序列，可以用极大似然估计进行阐述估计。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"EM 算法只有观测序列，无状态序列时来学习模型参数，即 Baum-Welch 算法。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"维特比算法是用动态规划解决 HMM 的预测问题的，不是参数估计。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"前向后向算法是用来计算概率的。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"极大似然估计是观测序列和相应序列都存在时的监督学习算法，用来进行阐参数估计。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"序列模式挖掘算法、AprioriAll 算法、GSP 算法、FreeSpan 算法、PrefixSpan 算法","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"Apriori 算法：关联分析原始算法，用于从候选项集中发现频繁项集。两个步骤：进行自连接、进行剪枝。缺点：无时序先后性。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"AprioriAll 算法：AprioriAll 算法与 Apriori 算法的执行过程是一样的，不同点在于候选集的产生，需要区分最后两个元素的前后。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"AprioriSome 算法：可以看做是 AprioriAll 算法的改进","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"AprioriAll 算法和 AprioriSome 算法的比较：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（1）AprioriAll 用  去计算出所有的候选 Ck，而 AprioriSome 会直接用  去计算所有的候选 ，因为 包含 ，所以 AprioriSome 会产生比较多的候选。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（2）虽然 AprioriSome 跳跃式计算候选，但因为它所产生的候选比较多，可能在回溯阶段前就占满内存。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（3）如果内存占满了，AprioriSome 就会被迫去计算最后一组的候选。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"（4）对于较低的支持度，有较长的大序列，AprioriSome 算法要好些。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"GPS算法：类Apriori算法。用于从候选项集中发现具有时序先后性的频繁项集。两个步骤：进行自连接、进行剪枝。缺点：每次计算支持度，都需要扫描全部数据集；对序列模式很长的情况，由于其对应的短的序列模式规模太大，算法很难处理。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"SPADE算法：改进的GPS算法，规避多次对数据集D进行全表扫描的问题。与GSP算法大体相同，多了一个IDLIST记录，使得每一次的IDLIST根据上一次的IDLIST得到（从而得到支持度）。而IDLIST的规模是随着剪枝的不断进行而缩小的。所以也就解决了GSP算法多次扫描数据集D问题。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"FreeSpan算法：即频繁模式投影的序列模式挖掘。核心思想是分治算法。基本思想为：利用频繁项递归地将序列数据库投影到更小的投影数据库集中，在每个投影数据库中生成子序列片断。这一过程对数据和待检验的频繁模式集进行了分割，并且将每一次检验限制在与其相符合的更小的投影数据库中。 优点：减少产生候选序列所需的开销。缺点：可能会产生许多投影数据库，开销很大，会产生很多的","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"PrefixSpan 算法：从FreeSpan中推导演化而来的。收缩速度比FreeSpan还要更快些。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"模型过拟合：","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"原因：（1）训练数据太少；（2）模型太复杂；（3）参数过多；（4）噪声过多。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"解决办法：（1）获得更多的训练数据；（2）降低特征维度；（3）正则化；（4）Dropout；（5）早停 Early Stop；（6）数据清洗。","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"参考","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"[1] GitHub 项目：ML-NLP；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"[2] XGBoost 特点、调参、讨论；","category":"page"},{"location":"AI/ML/","page":"-","title":"-","text":"[3] 诸葛越，葫芦娃，《百面机器学习》，中国工信出版集团，人民邮电出版社","category":"page"},{"location":"CV/contrast/#直方图统计","page":"对比度增强","title":"直方图统计","text":"","category":"section"},{"location":"CV/contrast/#直方图均衡化","page":"对比度增强","title":"直方图均衡化","text":"","category":"section"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"直方图均衡化（Histogram Equalization）可以增强图像对比度，主要的思想就是通过一个映射函数把一副图像的直方图分布变成近视均匀分布来提高图像的对比度，因此关键就是如何得到映射函数。","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"s_k=sum_j=0^k fracn_jn k=012cdots L-1","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"其中，s_k 是当前灰度级经过累积分布函数映射之后的值，n 是图像中像素的总和，n_j 是当前灰度级的像素个数，L 是图像中的灰度级别总数。","category":"page"},{"location":"CV/contrast/#基于空间熵的全局对比度增强（SEGCE）","page":"对比度增强","title":"基于空间熵的全局对比度增强（SEGCE）","text":"","category":"section"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"基于空间熵的灰度全局对比度增强（Spatial Entropy-Based Global Image Contrast Enhancement）通过计算图像的空间熵，得到一个可以拉伸像素值的映射函数，从而提高图像的对比度。","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"假设图像大小为 H times W，每个像素值为 x(i j)，SEGCE 的计算步骤如下：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"首先将图像 I 分成 M times N = K 个区域，对于每一个子区域 I =  i_1 i_2 dots i_k  计算灰度空间直方图：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"h_k =  h_k( m n ) mid 1 le m le M 1 le n le N ","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"其中 h_k(m n) 是 dots","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"N = leftlfloor left( fracKr right)^frac12 rightrfloor M = lfloor left( Kr right)^frac12 rfloor","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"计算空间熵：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"S_k = -sum_m-1^Msum_n-1^Nh_k(mn)log_2(h_k(mn))","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"计算离散函数 f_k","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"f_k = fracS_ksum_l=1lneq k^K S_l","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"离散函数 f_k 衡量灰度 k 相比其它灰度级的重要性。计算累计分布函数之前对齐进行归一化","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"f_k = fracf_ksum_l=1^Kf_l","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"计算累计分布函数 F(k)","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"F_k=sum_l=1^kf_l","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"将映射函数拉伸到 0 255，获取映射函数","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"y_k = lfloor F_k(y_u - y_d) + y_d rfloor","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"将原图像素利用映射函数得到新的对比度增强的图像。","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"应用问题总结：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"对灰度图计算映射函数，然后使用同一个函数分别对 BGR 三个通道进行计算，效果可以，缺点是会使得画面偏暗；\n对 BGR 三个通道分别计算映射函数，缺点是会导致偏色；","category":"page"},{"location":"CV/contrast/#自适应及集成领域依赖方法的非线性增强（AINDANE）","page":"对比度增强","title":"自适应及集成领域依赖方法的非线性增强（AINDANE）","text":"","category":"section"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"参考论文《Adaptive and integrated neighborhood-dependent approach for nonlinear enhancement of color images》，算法有三个步骤：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"全局曲线调整：根据图像亮度分布建立一个自适应的全局映射函数，作用是提高图像暗部像素值，压缩图像动态范围\n自适应对比度增强：根据像素领域内的平均值和线束值本身比例做映射，自适应增强对比度\n颜色恢复","category":"page"},{"location":"CV/contrast/#全局曲线调整","page":"对比度增强","title":"全局曲线调整","text":"","category":"section"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"计算出彩色图像的亮度值，可以有以下方法：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"YUV 空间的 Y 通道；\nHSL 空间的 L 分量；\n对比度保留去色；","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"论文里使用的公式如下：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"I(xy) = frac76245 I_R(xy) + 149685I_G(xy) + 2907I_B(xy)255","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"通过归一化后得到：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"I_n(xy) = fracI(xy)255","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"使用下面的映射函数来增强图像亮度：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"I^prime_n = fracI_n^(075z+025)+(1-I_n)04(1-z)+I_n^(2-z)2","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"其中参数 z 值由图像本身内容决定：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"z = begincases\n0                 textfor Lle 50      \nfracL-50100  textfor 50Lle 150  \n1                 textfor Lle 150       \nendcases","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"其中 L 表示亮度图像的累计直方图（CDF）达到 0.1 时的色阶值，即亮度图像中从小到大排序的前 90% 色阶值的最大值","category":"page"},{"location":"CV/contrast/#自适应对比度增强","page":"对比度增强","title":"自适应对比度增强","text":"","category":"section"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"全局对比度增强算法的思想是使得图像中亮的像素更亮，暗的像素更暗，提高了图像的动态范围，这与第一步的全局曲线调整是相反的。论文中提出的方法考虑了邻域的信息，如果当前的像素值比周边像素的平均值比较大的时候，增大当前像素值；如果当前的像素值比周边像素平均值比较小时，减小当前像素值。这种操作可以同时提高图像的对比度和细节、压缩图像动态范围。","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"邻域信息的计算可以用高斯模糊，对比度增强图像 S(xy) 的计算如下：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"S(xy) = 255I^prime_n(xy)^E(xy)","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"指数 Mask 计算如下：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"E(xy) = r(xy)^P = left fracI_textconv(xy)I(xy) right^P","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"其中 I_textconv(xy) 是对亮度图进行卷积后的结果，P 是衡量原始图像对比度的值，如果原始图像对比度比较差，P 值应该较大，可以通过计算原始图像亮度图的全局均方差来决定：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"P = begincases\n3                 textfor sigma le 3      \nfrac27-2sigma7  textfor 3Lle 10  \n1                 textfor sigma le 10       \nendcases","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"当卷积值 I_textconv(xy) 小于原始值 I(xy) 的时候，代表中心点亮度大于周边亮度，此时 E(xy)1，最终算得 S(xy)  I^prime_n(xy)，亮的会更亮；如果卷积值大于原始值，代表中心点亮度小于周边亮度，此时 E(xy)1，最终算得 S(xy)  I^prime_n(xy)，导致暗的地方更暗。","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"在这里可以做多个尺度的卷积和增强，来获取不同的领域信息。当尺度较小的时候，能够提高局部对比度，尺度较大时，虽然损失了细节，但是可以结合更多的全局信息。在多尺度下可以使用以下公式：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"S(xy) = sum_iw_i S_i(xy)","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"尺度的选择可以设置固定值，也可以根据图像大小进行自适应调整。","category":"page"},{"location":"CV/contrast/#颜色恢复","page":"对比度增强","title":"颜色恢复","text":"","category":"section"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"颜色恢复计算公式：","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"S_j(xy) = S(xy)fracI_j(xy)I(xy)lambda_j","category":"page"},{"location":"CV/contrast/","page":"对比度增强","title":"对比度增强","text":"通常 lambda=1 可以保证图像整体没有色彩偏移。","category":"page"},{"location":"#9Docs","page":"Home","title":"9Docs","text":"","category":"section"},{"location":"AI/GAN/#变分自编码器","page":"-","title":"变分自编码器","text":"","category":"section"},{"location":"AI/GAN/","page":"-","title":"-","text":"变分自编码器（Variational Autoencoder，VAE）与自编码器（Autoencoder，AE）在建模方面存在着很大的区别，本质上讲，VAE 是一种基于变分推断（Variational Inference）又叫变分贝叶斯方法（Variational Bayesian Methods）的概率模型，它属于无监督的生成模型。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"在变分推断中，除了已知的数据（观测数据、训练数据）之外，还存在一个隐含变量。假设有一个数据集 mathbfX=x^(i)，由 N 个连续变量或者离散变量 x 组成，还未观测的随机变量记为 z，那么数据产生包含两个过程：","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"从一个先验分布 p_theta(z) 中采样一个 z^(i)；\n根据条件分布 p_theta(xmid z)，用 z^(i) 生成 x^(i)；","category":"page"},{"location":"AI/GAN/#生成对抗网络","page":"-","title":"生成对抗网络","text":"","category":"section"},{"location":"AI/GAN/","page":"-","title":"-","text":"2014 年，加拿大蒙特利尔大学的 Ian Goodfellow 和他的导师 Yoshua Bengio 提出生成对抗网络（Generative Adversarial Networks, GANs）。在 GANs 被提出来之后，发展迅速，出现了各种变种网络，包括 WGAN、InfoGAN、f-GANs、BiGAN、DCGAN、IRGAN 等。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"对于 GANs 的理解，可以想象成假币者与警察间展开的一场猫捉老鼠游戏，造假币者试图造出以假乱真的假币，警察试图发现这些假币，对抗使得二者的水平都得到提高。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"GANs 包括生成器（Generator）和判别器（Discriminator）两个部分。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（1）生成器的作用是合成「假」样本。它从先验分布中采样随机信号，通过神经网络得到模拟样本。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（2）判别器的作用是判断输入的样本是真实的还是合成的。它同时接收来自生成器的模拟样本和实际数据集的真实样本，并且判断当前接收的样本是「真」还是「假」。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"GANs 实际上是一个二分类问题，判别器 D 试图识别实际数据为真实样本，识别生成器生成的数据为模拟样本。它的损失函数写成负对数似然 （Negative Log-Likelihood），也称为 Categorical Cross-Entropy Loss，即：","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"mathcalL(D) = -int p(x) left p(data mid x) log D(x) + p(g mid x) log(1-D(x))  righttextdxqquad text(1)","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"其中 D(x) 表示判别器预测 x 为真实样本的概率，p(data mid x) 和 p(g mid x) 表示 x 分属真实数据集和生成器这两类的概率。即理解为，在给定样本 x 的条件下，该样本来自真实数据集 data 的概率和来自生成器的概率。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"样本 x 的来源应该各占实际数据集和生成器一半，即 p_textsrc(data)=p_textsrc(g)= 05。用 p_textdata(x)doteq p(xmid data) 表示从实际数据集得到 x 的概率，p_textg(x)doteq p(xmid g) 表示从生成器得到 x 的概率，有 x 的总概率：","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"p(x) = p_textsrc(data)p(xmid data) + p_textsrc(g)p(xmid g)","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"注：doteq 和 approx 是等价的，都是表达约等于的意思。一般写完等号之后，发现不是等于，而是约等于，所以就懒得涂抹写成 approx，所以就添加一个点。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"将损失函数 (1) 式中的 p(x)p(datamid x) 替换为 p_textsrc(data)p_textdata(x)，以及将 p(x)p(gmid x) 替换为 p_textsrc(g)p_textg(x)，就可以得到最终的目标函数","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"mathcalD=-frac12left( mathbbE_xsim p_textdata(x)left log D(x) right + mathbbE_xsim p_textg(x)left log (1 - D(x)) rightright)","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"在此基础上可以得到值函数","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"V(GD) = mathbbE_xsim p_textdata(x)left log D(x) right + mathbbE_xsim p_textg(x)left log (1 - D(x)) right","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"在训练的时候，判别器 D 的目标就是最大化上述值函数，生成器 G 的目标就是最小化它，因此整个 MinMax 问题可以表示为 undersetGminundersetDmax V(GD)。","category":"page"},{"location":"AI/GAN/#GANs-的训练方式","page":"-","title":"GANs 的训练方式","text":"","category":"section"},{"location":"AI/GAN/","page":"-","title":"-","text":"我们知道 GANs 的值函数为","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"V(GD) = mathbbE_xsim p_textdata(x)left log D(x) right + mathbbE_xsim p_textg(x)left log (1 - D(x)) right","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"在训练的时候，判别器 D 的目标就是最大化上述值函数，生成器 G 的目标就是最小化它，因此整个 MinMax 问题可以表示为 undersetGminundersetDmax V(GD)。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"GANs 在训练的时候是采用生成器和判别器交替优化的方式进行的。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"判别器 D 的训练：","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（1）先固定生成器 G(cdot)；","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（2）利用生成器随机模拟产生样本 G(z) 作为负样本（z 是一个随机向量），并从真实数据集中采样获得正样本 X；","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（3）将正负样本输入到判别器 D(cdot) 中，根据判别器的输出 D(X) 和 D(G(z)) 和样本标签来计算误差；","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（4）最后利用误差反向传播算法来更新判别器 D(cdot) 的参数；","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"判别器的训练是这样的一个问题：给定生成器 G，寻找当前情况下的最优判别器 D^*_G 。对于单个样本 x，最大化 undersetDmax p_textdata(x)log D(x) + p_textg(x)log(1-D(x)) 的解为 hatD(x)=p_textdata(x)p_textdata(x)+p_textg(x)，外面套上对 x 的积分就得到 undersetDmax V(GD)，解由单点变成一个函数解：","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"D^*_G=fracp_textdatap_textdata+p_textg","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"此时 undersetGminV(GD^*_G)=undersetGminleft-log 4 + 2cdot textJSD(p_textdata p_textg)right，其中 textJSD(cdot) 是 JS 距离。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"优化生成器 G 实际上是在最小化生成样本分布与真实样本分布的 JS 距离。最终达到的均衡点是 textJSD(p_textdata p_textg) 的最小值点，即 p_textg=p_textdata 时，textJSD(p_textdata p_textg) 取到零，最优解 G^*(z)=xsim p_textdata(x)，D^*(x)equiv frac12，值函数 V(G^*D^*)=-log 4。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"生成器 G 的训练：","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（1）先固定判别器 D(cdot)；","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（2）然后利用当前生成器 G(cdot) 随机模拟产生样本 G(z)，输入到判别器 G(cdot) 中；","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（3）根据判别器的输出 D(G(z)) 和样本标签来计算误差；","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"（4）最后利用误差反向传播算法来更新生成器 G(cdot) 的参数；","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"假设 G^prime 表示前一步的生成器，D 是 G^prime 下的最优判别器 D^*_G^prime。那么求解最优生成器 G 的过程为：","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"undersetGargminV(GD^*_G^prime)=undersetGargmintextKLleft( p_textg  fracp_textdata+p_textg^prime2 right) - textKL(P_textg P_textg^prime)","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"由此可以知道（1）优化 G 的过程是让 G 远离前一步的 G^prime，同时接近分布 (p_textdata+p_textg^prime)2；（2）达到均衡点时 p_textg^prime=p_textdata，有 undersetGargminV(GD^*_G^prime)=undersetGargmin()，如果用这时的判别器去训练一个全新的生成器 G_textnew，理论上可能啥也训练不出来。","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"参考：","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"[1] 诸葛越，葫芦娃，《百面机器学习》，中国工信出版集团，人民邮电出版社","category":"page"},{"location":"AI/GAN/","page":"-","title":"-","text":"[2] Goodfellow I. J., Pouget-Abadie J., Mirza M., et al. Generative adversarial networks[J]. Advances in Neural Information Processing Systems, 2014, 3: 2672-2680. ","category":"page"},{"location":"CV/dark_channel_prior/#暗通道先验","page":"暗通道先验去雾","title":"暗通道先验","text":"","category":"section"}]
}
