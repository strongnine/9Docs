<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>- · 9Docs</title><meta name="title" content="- · 9Docs"/><meta property="og:title" content="- · 9Docs"/><meta property="twitter:title" content="- · 9Docs"/><meta name="description" content="Documentation for 9Docs."/><meta property="og:description" content="Documentation for 9Docs."/><meta property="twitter:description" content="Documentation for 9Docs."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">9Docs</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">深度学习</span><ul><li><a class="tocitem" href="../../DL/CNN/">卷积神经网络</a></li><li><a class="tocitem" href="../../DL/stereo/">立体匹配</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>-</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>-</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/strongnine/9Docs" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/strongnine/9Docs/blob/main/docs/src/AI/GAN.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h2 id="变分自编码器"><a class="docs-heading-anchor" href="#变分自编码器">变分自编码器</a><a id="变分自编码器-1"></a><a class="docs-heading-anchor-permalink" href="#变分自编码器" title="Permalink"></a></h2><p>变分自编码器（Variational Autoencoder，VAE）与自编码器（Autoencoder，AE）在建模方面存在着很大的区别，本质上讲，VAE 是一种基于变分推断（Variational Inference）又叫变分贝叶斯方法（Variational Bayesian Methods）的概率模型，它属于无监督的生成模型。</p><p>在变分推断中，除了已知的数据（观测数据、训练数据）之外，还存在一个隐含变量。假设有一个数据集 <span>$\mathbf{X}=\{x^{(i)}\}$</span>，由 <span>$N$</span> 个连续变量或者离散变量 <span>$x$</span> 组成，还未观测的随机变量记为 <span>$z$</span>，那么数据产生包含两个过程：</p><ul><li>从一个先验分布 <span>$p_{\theta}(z)$</span> 中采样一个 <span>$z^{(i)}$</span>；</li><li>根据条件分布 <span>$p_{\theta}(x\mid z)$</span>，用 <span>$z^{(i)}$</span> 生成 <span>$x^{(i)}$</span>；</li></ul><h2 id="生成对抗网络"><a class="docs-heading-anchor" href="#生成对抗网络">生成对抗网络</a><a id="生成对抗网络-1"></a><a class="docs-heading-anchor-permalink" href="#生成对抗网络" title="Permalink"></a></h2><p>2014 年，加拿大蒙特利尔大学的 Ian Goodfellow 和他的导师 Yoshua Bengio 提出生成对抗网络（Generative Adversarial Networks, GANs）。在 GANs 被提出来之后，发展迅速，出现了各种变种网络，包括 WGAN、InfoGAN、f-GANs、BiGAN、DCGAN、IRGAN 等。</p><p>对于 GANs 的理解，可以想象成假币者与警察间展开的一场猫捉老鼠游戏，造假币者试图造出以假乱真的假币，警察试图发现这些假币，对抗使得二者的水平都得到提高。</p><p>GANs 包括<strong>生成器（Generator）</strong>和<strong>判别器（Discriminator）</strong>两个部分。</p><p>（1）生成器的作用是合成「假」样本。它从先验分布中采样随机信号，通过神经网络得到模拟样本。</p><p>（2）判别器的作用是判断输入的样本是真实的还是合成的。它同时接收来自生成器的模拟样本和实际数据集的真实样本，并且判断当前接收的样本是「真」还是「假」。</p><p>GANs 实际上是一个二分类问题，判别器 <span>$D$</span> 试图识别实际数据为真实样本，识别生成器生成的数据为模拟样本。它的损失函数写成<strong>负对数似然 （Negative Log-Likelihood）</strong>，也称为 Categorical Cross-Entropy Loss，即：</p><p class="math-container">\[\mathcal{L}(D) = -\int p(x) \left[ p(data \mid x) \log D(x) + p(g \mid x) \log(1-D(x))  \right]\,\text{d}x,\qquad \text{(1)}\]</p><p>其中 <span>$D(x)$</span> 表示判别器预测 <span>$x$</span> 为真实样本的概率，<span>$p(data \mid x)$</span> 和 <span>$p(g \mid x)$</span> 表示 <span>$x$</span> 分属真实数据集和生成器这两类的概率。即理解为，在给定样本 <span>$x$</span> 的条件下，该样本来自真实数据集 <span>$data$</span> 的概率和来自生成器的概率。</p><p>样本 <span>$x$</span> 的来源应该各占实际数据集和生成器一半，即 <span>$p_{\text{src}}(data)=p_{\text{src}}(g)= 0.5$</span>。用 <span>$p_{\text{data}}(x)\doteq p(x\mid data)$</span> 表示从实际数据集得到 <span>$x$</span> 的概率，<span>$p_{\text{g}}(x)\doteq p(x\mid g)$</span> 表示从生成器得到 <span>$x$</span> 的概率，有 <span>$x$</span> 的总概率：</p><p class="math-container">\[p(x) = p_{\text{src}}(data)p(x\mid data) + p_{\text{src}}(g)p(x\mid g).\]</p><blockquote><p>注：<span>$\doteq$</span> 和 <span>$\approx$</span> 是等价的，都是表达约等于的意思。一般写完等号之后，发现不是等于，而是约等于，所以就懒得涂抹写成 <span>$\approx$</span>，所以就添加一个点。</p></blockquote><p>将损失函数 (1) 式中的 <span>$p(x)p(data\mid x)$</span> 替换为 <span>$p_{\text{src}}(data)p_{\text{data}}(x)$</span>，以及将 <span>$p(x)p(g\mid x)$</span> 替换为 <span>$p_{\text{src}}(g)p_{\text{g}}(x)$</span>，就可以得到最终的目标函数</p><p class="math-container">\[\mathcal{D}=-\frac{1}{2}\left( \mathbb{E}_{x\sim p_{\text{data}}(x)}\left[ \log D(x) \right] + \mathbb{E}_{x\sim p_{\text{g}}(x)}\left[ \log (1 - D(x)) \right]\right),\]</p><p>在此基础上可以得到值函数</p><p class="math-container">\[V(G,D) = \mathbb{E}_{x\sim p_{\text{data}}(x)}\left[ \log D(x) \right] + \mathbb{E}_{x\sim p_{\text{g}}(x)}\left[ \log (1 - D(x)) \right].\]</p><p>在训练的时候，判别器 <span>$D$</span> 的目标就是最大化上述值函数，生成器 <span>$G$</span> 的目标就是最小化它，因此整个 MinMax 问题可以表示为 <span>$\underset{G}{\min}\underset{D}{\max} V(G,D)$</span>。</p><h3 id="GANs-的训练方式"><a class="docs-heading-anchor" href="#GANs-的训练方式">GANs 的训练方式</a><a id="GANs-的训练方式-1"></a><a class="docs-heading-anchor-permalink" href="#GANs-的训练方式" title="Permalink"></a></h3><p>我们知道 GANs 的值函数为</p><p class="math-container">\[V(G,D) = \mathbb{E}_{x\sim p_{\text{data}}(x)}\left[ \log D(x) \right] + \mathbb{E}_{x\sim p_{\text{g}}(x)}\left[ \log (1 - D(x)) \right].\]</p><p>在训练的时候，判别器 <span>$D$</span> 的目标就是最大化上述值函数，生成器 <span>$G$</span> 的目标就是最小化它，因此整个 MinMax 问题可以表示为 <span>$\underset{G}{\min}\underset{D}{\max} V(G,D)$</span>。</p><p>GANs 在训练的时候是采用生成器和判别器交替优化的方式进行的。</p><p><strong>判别器 <span>$D$</span> 的训练</strong>：</p><p>（1）先固定生成器 <span>$G(\cdot)$</span>；</p><p>（2）利用生成器随机模拟产生样本 <span>$G(z)$</span> 作为负样本（<span>$z$</span> 是一个随机向量），并从真实数据集中采样获得正样本 <span>$X$</span>；</p><p>（3）将正负样本输入到判别器 <span>$D(\cdot)$</span> 中，根据判别器的输出 <span>$D(X)$</span> 和 <span>$D(G(z))$</span> 和样本标签来计算误差；</p><p>（4）最后利用误差反向传播算法来更新判别器 <span>$D(\cdot)$</span> 的参数；</p><p>判别器的训练是这样的一个问题：给定生成器 <span>$G$</span>，寻找当前情况下的最优判别器 <span>$D^*_G$</span> 。对于单个样本 <span>$x$</span>，最大化 <span>$\underset{D}{\max} p_{\text{data}}(x)\log D(x) + p_{\text{g}}(x)\log(1-D(x))$</span> 的解为 <span>$\hat{D}(x)=p_{\text{data}}(x)/[p_{\text{data}}(x)+p_{\text{g}}(x)]$</span>，外面套上对 <span>$x$</span> 的积分就得到 <span>$\underset{D}{\max} V(G,D)$</span>，解由单点变成一个函数解：</p><p class="math-container">\[D^*_G=\frac{p_{\text{data}}}{p_{\text{data}}+p_{\text{g}}}.\]</p><p>此时 <span>$\underset{G}{\min}V(G,D^*_G)=\underset{G}{\min}\left\{-\log 4 + 2\cdot \text{JSD}(p_{\text{data}}\| p_{\text{g}})\right\}$</span>，其中 <span>$\text{JSD}(\cdot)$</span> 是 JS 距离。</p><p>优化生成器 G 实际上是在最小化生成样本分布与真实样本分布的 JS 距离。最终达到的均衡点是 <span>$\text{JSD}(p_{\text{data}}\| p_{\text{g}})$</span> 的最小值点，即 <span>$p_{\text{g}}=p_{\text{data}}$</span> 时，<span>$\text{JSD}(p_{\text{data}}\| p_{\text{g}})$</span> 取到零，最优解 <span>$G^*(z)=x\sim p_{\text{data}}(x)$</span>，<span>$D^*(x)\equiv \frac{1}{2}$</span>，值函数 <span>$V(G^*.D^*)=-\log 4$</span>。</p><p><strong>生成器 <span>$G$</span> 的训练</strong>：</p><p>（1）先固定判别器 <span>$D(\cdot)$</span>；</p><p>（2）然后利用当前生成器 <span>$G(\cdot)$</span> 随机模拟产生样本 <span>$G(z)$</span>，输入到判别器 <span>$G(\cdot)$</span> 中；</p><p>（3）根据判别器的输出 <span>$D(G(z))$</span> 和样本标签来计算误差；</p><p>（4）最后利用误差反向传播算法来更新生成器 <span>$G(\cdot)$</span> 的参数；</p><p>假设 <span>$G^\prime$</span> 表示前一步的生成器，<span>$D$</span> 是 <span>$G^\prime$</span> 下的最优判别器 <span>$D^*_{G^\prime}$</span>。那么求解最优生成器 <span>$G$</span> 的过程为：</p><p class="math-container">\[\underset{G}{\arg\min}\,V(G,D^*_{G^\prime})=\underset{G}{\arg\min}\,\text{KL}\left( p_{\text{g}} \| \frac{p_{\text{data}}+p_{\text{g}^\prime}}{2} \right) - \text{KL}(P_{\text{g}}\| P_{\text{g}^\prime}).\]</p><p>由此可以知道（1）优化 <span>$G$</span> 的过程是让 <span>$G$</span> 远离前一步的 <span>$G^\prime$</span>，同时接近分布 <span>$(p_{\text{data}}+p_{\text{g}^\prime})/2$</span>；（2）达到均衡点时 <span>$p_{\text{g}^\prime}=p_{\text{data}}$</span>，有 <span>$\underset{G}{\arg\min}\,V(G,D^*_{G^\prime})=\underset{G}{\arg\min}\,()$</span>，如果用这时的判别器去训练一个全新的生成器 <span>$G_\text{new}$</span>，理论上可能啥也训练不出来。</p><hr/><p><strong>参考</strong>：</p><p>[1] 诸葛越，葫芦娃，《百面机器学习》，中国工信出版集团，人民邮电出版社</p><p>[2] Goodfellow I. J., Pouget-Abadie J., Mirza M., et al. Generative adversarial networks[J]. Advances in Neural Information Processing Systems, 2014, 3: 2672-2680. </p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Monday 6 October 2025 16:26">Monday 6 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
