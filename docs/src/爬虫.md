爬虫三步：

- 拿到页面源代码 `requests`；
- 通过 xpath 提取有效的信息 `lxml`；
- 保存数据；

拿到页面源代码需要先有 `url`，`header` 是模拟浏览器的。

`header` 的获取，可以在登录 `url` 的时候，`F12` 切换到 Network 的界面，随便找到一个请求，然后在 Headers 上找到 `User-Agent` 直接复制使用：

```python
headers = {
    "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
}


```

